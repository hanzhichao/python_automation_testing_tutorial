上一章学习了接口测试工具的使用，如何抓包以及怎样使用Postman手工测试各种接口。手工测试是自动化测试的基础，当我们使用Postman调通各个接口，清楚接口的各种场景下的返回值后，就可以开始使用代码实现接口测试的自动化。一般情况下，接口服务相对稳定，在每个迭代版本中有大量的回归工作。自动化测试脚本可以7\*24小时值守，帮我们监控及定时验证接口服务的正确性。
本章带领大家学习使用Python的第三方requests库构造和发送各种HTTP请求，学习如何处理接口依赖，异步接口，如何进行数据的参数化，如何解析JSON/XML/HTML格式的响应信息，以及断言的一些策略。
## 2.1  使用Requests发送请求
Python3自带的http.client以及urllib.request库都能发送HTTP请求，不过相对来说，以人为本的第三方requests库使用起来更方便。支持HTTPS,内容自动编码界面，会话保持，长连等。
优点如下：
- Keep-Alive & 连接池
- 国际化域名和 URL
- 带持久 Cookie 的会话
- 浏览器式的SSL认证
- 自动内容解码
- 基本/摘要式的身份认证
- 优雅的key/value Cookie
- 自动解压
- Unicode 响应体
- HTTP(S) 代理支持
- 文件分块上传
- 流下载
- 连接超时
- 分块请求
- 支持 .netrc
官方文档：https://requests.readthedocs.io/zh_CN/latest/
### 2.1.1  安装方法
在安装了Python3环境和pip包管理器的情况下，我们可以直接在终端或命令行使用以下命令安装requests:
```bash
$ pip install requests
```
验证是否安装成功:
```bash
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 05:52:31)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> import requests
>>> 
```
打开命令行，输入python或python3，在Python Shell环境下输入import requests，没有报错即安装成功。
### 2.1.2  发送GET请求
GET请求是最常见的接口，通常用来获取数据。使用requests发送一个请求通常分为3步，组装请求、发送请求并获取响应、解析响应。
1. 组装请求：请求可能包含url，params(url参数)，data(请求数据)，headers(请求头)，cookies等，最少必须有url。
2. 发送请求并获取响应：支持get，post等各种方法发送，返回的是一个响应对象。
3. 解析响应：获取状态码、响应文本、响应头、响应时间等数据。
组装请求即组装requests请求方法需要的url,params,data,json等响应格式参数数据，使用requests的get方法发送请求，返回一个响应体对象，我们通过响应体对象的status_code,text,headers,cookies获取相应的响应信息，示例如下：

> 代码requests_get.py内容
```python
import requests

url = 'https://httpbin.org/get?name=临渊&age=18'
res = requests.get(url)
print('状态码', res.status_code)
print('响应文本', res.text)
print('响应头', res.headers)
print('响应时间', res.elapsed)
```
首先需要导入requests包。
第一步，组装请求：GET请求一般只需要一个URL参数，字符串格式。URL查询参数可以直接写在URL中。
第二步，发送请求斌过去响应：将接口的URL传入requests的get()方法即可，该方法返回一个响应对象，我们将返回的响应对象赋给变量res。
第三步，解析响应：可以通过响应对象res的不同属性和方法来获取不同的响应信息。例如，通过res.status_code可以获取到状态码，通过res.text可以获取响应数据（默认为unicode编码后的文本格式），通过res.headers可以获取到响应头信息，通过res.elapsed可以获取到响应时间信息。
运行结果如下：
```
状态码 200
响应文本 {
  "args": {
    "age": "18",
    "name": "\u4e34\u6e0a"
  },
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.18.4"
  },
  "origin": "111.194.126.253, 111.194.126.253",
  "url": "https://httpbin.org/get?name=\u4e34\u6e0a&age=18"
}
响应头 {'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Origin': '*', 'Content-Encoding': 'gzip', 'Content-Type': 'application/json', 'Date': 'Mon, 20 Jan 2020 02:33:47 GMT', 'Referrer-Policy': 'no-referrer-when-downgrade', 'Server': 'nginx', 'X-Content-Type-Options': 'nosniff', 'X-Frame-Options': 'DENY', 'X-XSS-Protection': '1; mode=block', 'Content-Length': '222', 'Connection': 'keep-alive'}
响应时间 0:00:00.908001
```

>注：URL只支持ASCII(美国标准码)，在实际的传输过程中，中文及一些特殊字符需要经过urlencoded(URL编码)。如上例中的接口地址会被编码成：
https://httpbin.org/get?name=%E4%B8%B4%E6%B8%8A&age=18

requests在发送请求时会自动完成编码。

#### 使用独立Params
Params又叫Query Params，即URL参数，如?name=临渊&age=18。如果参数很多，直接写到URL中会比较长，不方便查看和修改。URL参数由多组键值对组成，可以通过字典传给requests请求的params参数，示例如下：
代码requests_get_with_params.py内容
```python
import requests

url = 'https://httpbin.org/get'
url_params = {'name': '临渊', 'age': '18'}
res = requests.get(url, params=url_params)
try:
    res_dict = res.json()
    print('响应文本转为字典', res_dict)
    print('提取响应数据args', res_dict.get('args'))
except:
    print('响应文本', res.text) 
```
第一步，组装请求：这里除了组装了字符串格式的URL参数外，还单独组装了字典格式的请求参数。
第二步，发送请求并获取响应对象：请求方法的第一个参数传入url，组装的字典格式的请求参数要传给请求方法的params参数。这是一种固定用法，当请求方法的params参数接收到字典格式的传值后，会自动进行特定的编码和组装。
第三步，响应解析：对应返回JSON格式的响应，可以使用响应对象的json()方法，将文本格式的数据转为Python字典格式，以方便提取相应字段的值。

运行结果如下：
```bash
响应文本转为字典 {'args': {'age': '18', 'name': '临渊'}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.22.0', 'X-Amzn-Trace-Id': 'Root=1-5e5c8d74-23e0d5c89d91e520e238f554'}, 'origin': '114.246.34.10', 'url': 'https://httpbin.org/get?name=临渊&age=18'}
提取响应数据args {'age': '18', 'name': '临渊'}
```

> 注：HTTP的请求和响应都是通过Byte字符串传输的，发送要转为Bype字符串发送，收到的响应内容也是Byte字符串格式，响应内容通过res.text将Byte字符串按utf-8模式解码成字符串格式的响应文本，然后通过res.json()将响应文本转为字典格式。
res.json()方法实际上是使用了json.loads(res.text)将响应文本尝试以JSON格式转为字典。由于该方法存在异常（比如正常情况下返回JSON格式，500报错时则会返回非JSON格式的报错信息），因此建议使用try...except处理。

#### 使用请求头
请求头是链接和请求数据的一些辅助说明信息，常见的请求头有：
- Accept：客户端能接受的内容类型。
- Accept-Charset：浏览器可以接受的字符编码。
- Accept-Encoding：浏览器可以支持的压缩编码类型。
- Accept-Languge：浏览器可以接受的语言。
- Referer：连接来路。
- User-Agent：发送请求的客户端信息。
- Connection：连接类型（Keepalive保持连接/Close关闭连接）。
- X-Requested-With：XMLHttpRequest(是Ajax异步请求)。
- Cookie：服务器标记信息。
- Cache-Control：缓存机制（no-cache无缓存或max-age=缓存保存时间）。
- Expries：缓存过期时间。
- Content-Type：内容类型（MIME类型）。
- Content-Length：数据长度。
通常情况下，请求头还用于身份验证，如通过Cookie或额外的Token字段等。因此有时候发送请求时需要携带特定的请求头信息。请求头一般有一组组键值对组成，我们同样使用Python中的的字典格式，构造出请求头数据，并传递给请求方法的headers参数即可，示例如下：

> 代码requests_get_with_headers.py内容
```python
import requests
url = 'https://httpbin.org/get'
headers = {
    'Cookie': 'sessionid=123456;token=abcdef'
}
res = requests.get(url, headers=headers)
print(res.text)
```
组装请求时，组装字符串格式的url和字典格式的headers。请求方法中的headers=headers，第一个headers是请求方法的固定参数，第二个headers是我们自定义的字典变量（也可以使用其他名称），执行后打印信息如下：
```
{
  "args": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Cookie": "sessionid=123456;token=abcdef",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.22.0",
    "X-Amzn-Trace-Id": "Root=1-5e5cff1a-1182dab4bd7caf104ccdcac4"
  },
  "origin": "114.246.34.10",
  "url": "https://httpbin.org/get"
}
```

>注：请求头项一般不区分大小写。Cookie是请求头的一项（注意为单数形式），可以通过登录后抓包获取Cookie，并携带Cookie来实现模拟登录状态。整个Cookie作为一个支付串整体传入，不需要拆分。

#### 使用Cookies
Cookies可以作为一个整体的字符串放到请求头的Cookie字段中，当Cookies很多并且需要组装时，使用字符串会比较长并难以维护。此时可以将Cookies拆开成一组组键值对，构造为字典格式的数据，传递给请求方法的cookies参数，示例如下：

> 代码requests_with_cookies.py内容
```python
import requests
url = 'https://httpbin.org/get'
cookies = {
    'sessionid': '123456',
    'token': 'abcdef'
}
res = requests.get(url, cookies=cookies)
print(res.text)
```
组装请求时，组装了字典格式的cookies变量，并传递给请求方法的cookies参数。使用字典方式来构造cookies的好处在于，结构清晰，方便更新和修改。运行后结果同上例相同。

>注：Cookies中不能拥有非ASCII字符，中文应进行URL编码后使用。
### 发送POST请求
POST方法和GET方法本质上一样的，都是HTTP请求的一种请求动作。只是通常情况下GET请求不使用请求体数据，而POST使用。既然POST方法会发送请求体数据，就会涉及到数据类型的问题。客户端和服务端商量好，才能正常的解析和通讯。这种数据类型又称为媒体类型，标准称法为MIME（Multipurpose Internet Mail Extensions）类型，即多用途互联网邮件扩展类型。数据类型的声明，一般放在请求头（请求辅助信息）的Content-Type字段中，常见的有以下几种格式。
- application/x-www-form-urlencoded：表单URL编码格式
- multipart/form-data：复合表单格式（支持文件上传，文件二进制
- application/json：JSON格式
- application/xml：XML格式
不同数据类型的请求，数据组装方式也不同，至于什么时候用表单，什么时候用JSON格式要看接口文档或问开发小哥哥，接口在编写时便已确定好了需要使用的的数据（媒体）类型。
发送POST请求使用requests的post方法即可，格式如下：
res = requests.post(url,data={}, json={}, files={})
data、json、files都是可选参数（一般同时只用其中一个）。分别用来将数据按不同格式编码发送。
- data参数接受字典时将数据按普通表单（application/x-www-form-urlencoded）格式发送。
- json参数存在时将字典格式的请求数据按JSON格式（application/json）发送
- files参数将字典格式的请求数据（可以包含打开的文件）按混合表单（multipart/form-data）格式发送。
使用三者之一时，会自动在请求头中添加对应的内容类型声明，一般情况下，只使用data参数或json参数即可，files参数也可以和data参数组合使用。

> 注：data参数由3种使用方式，当data参数接收一个字典参数时，按表单格式发送请求。当data参数接收字符串格式的参数时，按原始文本（Raw）格式发送请求，不进行编码和添加请求头。当data参数接收打开的文件对象时，按binary二进制格式发送请求。

#### 发送FORM表单格式数据
Form表单指网页中包含输入框、选择框、按钮等组成的一组用户填写及选择的数据。如登录、注册表单。表单是最常用的一种请求数据类型，对应的请求头媒体类型声明：Content-Type: application/x-www-form-urlencoded。
之所以称为urlencoded，是因为，请求体数据，实际会按url编码格式发送，如name=临渊，password=123456实际上会编码为 name=%E4%B8%B4%E6%B8%8A&password=123456作为请求体数据，后台传输。
表单类型的参数同样是由多组键值对组成，我们同样适用字典格式构造请求体数据并传递给请求方法的data参数即可，示例如下：
代码requests_post_form.py内容
```python
import requests
url = 'https://httpbin.org/post'
data = {'name': '临渊', 'password': '123456'}
res = requests.post(url, data=data)
print(res.text)
```
发送POST请求只要使用requests.post()方法即可，方法中的data=data，第一个data是请求方法的一个固定的关键字参数，后面的data是上面我自定义的变量，即{'name': '临渊', 'password': '123456'}，使用其他变量名可以。打印结果如下：
```json
{
  "args": {},
  "data": "",
  "files": {},
  "form": {
    "name": "\u4e34\u6e0a",
    "password": "123456"
  },
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Content-Length": "39",
    "Content-Type": "application/x-www-form-urlencoded",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.18.4"
  },
  "json": null,
  "origin": "111.194.126.253, 111.194.126.253",
  "url": "https://httpbin.org/post"
}
```

发送时，请求头中会自动添加"Content-Type": "application/x-www-form-urlencoded"。 对于JSON格式的响应数据，我们可以使用res.json()转为字典格式并通过字典取值提取响应字段的变量进行断言。假python设我们要断言响应结果的url为"https://httpbin.org/post"，form不为空且name和password是我们传的值，示例如下：
```python
res_dict = res.json()
form = res_dict.get('form')
assert "https://httpbin.org/post" == res_dict.get('url')
assert form and "临渊" == form.get('name') and '123456' == form.get('password')
```
再次运行，结果和上次一致。没有报错即为assert断言通过，断言失败时会报AssertionError。

#### 发送JSON格式数据
JSON格式是一种通用的数据格式，在Python中JSON实际为“符合JSON语法格式的字符串”，本质是str类型。JSON格式和Python的字典一一对应，略有不同，如JSON中的true/false/null对应字典中的True/False/None。我们同样可以使用字典来构造JSON请求的数据，然后传递够请求方法的json参数即可，示例如下：

> 代码requests_post_json.py内容
```python
import requests
url = 'https://httpbin.org/post'
json_data = {'name': '临渊', 'age': 18, 'on_site': True, 'favorite': None}
res = requests.post(url, json=json_data)
print(res.text)
```

URL参数和FORM变动格式中的数字实际都是转为字符串格式去发送的，而JSON中可以区分数字格式和字符串格式。如{"age": 18}和{"age":"18"}有可能是不一样的。响应文本打印结果如下：
```json
{
  "args": {},
  "data": "{\"name\": \"\\u4e34\\u6e0a\", \"age\": 18, \"on_site\": true, \"favorite\": null}",
  "files": {},
  "form": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Content-Length": "70",
    "Content-Type": "application/json",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.18.4"
  },
  "json": {
    "age": 18,
    "favorite": null,
    "name": "\u4e34\u6e0a",
    "on_site": true
  },
  "origin": "111.194.126.253, 111.194.126.253",
  "url": "https://httpbin.org/post"
}
```
发送时，请求头中会自动添加"Content-Type": "application/json"。 细心的同学会发现，FORM表单格式发送的数据会出现在响应的form字段中，JSON格式的却出现在data字段中。这是因为JSON和XML等格式一样属于Raw（原始格式），即原样发送。但是在实际发送时仍要确保请求数据都转为ASCII（美国标准码）来传输。因此中文参数“临渊”在传输是会按utf-8编码转换为“\u4e34\u6e0a”。由于JSON格式中只能使用双引号，响应中data参数是一个JSON格式的字符串，需要使用转义字符“\”。

#### 发送XML格式的数据
上例提到XML和JSON都属于Raw格式的数据，XML和JSON在Python中实际都是不同格式的文本字符串。我们将字符串传递给请求方法的data参数即可按Raw格式原样发送，此时如果请求数据中有非ASCII码还需要自己编码并在请求头中添加相应的内容类型说明（Content-Type）。
因此，发送XML格式的数据，可以读取XML文件内容，或使用多行字符串构造XML请求数据，并传递给请求方法的data参数，示例如下：

> 代码requests_post_xml.py内容
```python
import requests
url = 'https://httpbin.org/post'
xml_data = '''
<xml>
    <name>临渊</name>
    <age>12</name>
</xml>
'''
headers = {'Content-Type': 'application/xml'}
res = requests.post(url, data=xml_data.encode('utf-8'), headers=headers)
print(res.text)
```
由于xml_data数据中存在非ASCII码，需要将数据按utf-8格式编码为Byte字符串发送。由于使用Raw格式发送数据时不会自动添加请求头，因此需要手动在请求头中添加内容类型声明，并将构造的字典类型的请求头变量，传递给请求方法的关键字参数headers。响应结果如下：
```json
{
  "args": {},
  "data": "\n<xml>\n    <name>\u4e34\u6e0a</name>\n    <age>12</name>\n</xml>\n",
  "files": {},
  "form": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Content-Length": "57",
    "Content-Type": "application/xml",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.18.4"
  },
  "json": null,
  "origin": "111.194.126.253, 111.194.126.253",
  "url": "https://httpbin.org/post"
}
```
以上示例响应的data字段中存储的就是通过Raw格式（包括JSON格式）发送的请求数据。
Raw格式的请求（Text、JavaScript、JSON、XML、HTML等）都可以按这种方式发送。JSON请求同样也可以按原始方式发送，示例如下：

> 代码requests_post_raw_json.py内容
```python
import requests
url = 'https://httpbin.org/post'
json_data_str = '''
{
    "name": "临渊",
    "age": 18,
    "on_site": true,
    "favorite": null
}
'''
headers = {'Content-Type': 'application/json'}
res = requests.post(url, data=json_data_str.encode('utf-8'), headers=headers)
print(res.text)
```

> 注：以上的json_data_str须是符合JSON格式的字符串，包括必须使用双引号，应该使用小写的true，无值应该是null，由于字符串中存在中文，同样要手动进行encode编码，同时要手动添加请求头指定内容类型。

为方便构造请求数据，也可以先构造一个字典格式的请求数据，再使用json.dumps()，将字典格式的数据转为JSON字符串发送，示例如下：

> 代码requests_post_raw_json2.py内容
```python
import requests
import json
url = 'https://httpbin.org/post'
json_data = {
    'name': '临渊',
    'age': 18,
    'on_site': True,
    'favorite': None
}
headers = {'Content-Type': 'application/json'}
res = requests.post(url, data=json.dumps(json_data), headers=headers)
print(res.text)
```
>注：以上json_data是字典格式的变量，因此要使用True及None。在将字典转为JSON字符串时，需要首先导入json库。json.dumps()将字典格式的json_data转换为JSON字符串，并通过默认的ensure_ascii=True参数将中文转换为\u形式的ASCII字符（如“临渊”会转换为“\u4e34\u6e0a”），因此不再需要进行编码后发送。

#### 发送Multipart/form-data请求（文件上传）
网页上的表单有两种，一种是不包含文件上传，所有用户输入或选择的数据都可以使用字符串格式表示，这种称为普通表单或纯文本表单，对应MIME类型为application/x-www-form-urlencoded。
另一种即包括普通输入框等，也包含一个或多个文件上传框。普通输入框中的变量值可以已字符串格式编码，而上传的文件（如图片文件）则不一定能直接转为字符串，要使用二进制格式。因此要使用多部分的混合格式，笔者称之为混合表单，对应MIME类型为multipart/form-data。在表单中，每个需要上传的文件和普通输入框一样对应一个指定的变量。因此同样可以使用字典格式组装混合表单的请求数据传递给请求方法的files参数即可，示例如下：

> 代码requests_post_file.py内容
```python
import requests
url = 'https://httpbin.org/post'
data = {'name': '临渊', 'age': 18}
multi_form_data = {
    'avatar': open('/Users/apple/Pictures/robot.png', 'rb'),
    'avatar2': open('/Users/apple/Pictures/robot.jpg', 'rb'),
}
res = requests.post(url, data=data, files=multi_form_data)
print(res.text)
```
表单数据中的数字要使用字符串格式的数字，文件要以rb二进制格式打开传输，支持多个变量以及多个文件。
文件类型的数据avatar可以只穿一个打开的文件对象open('/Users/apple/Pictures/robot.png', 'rb')，也可以传递三个参数：要保存的文件名，打开的文件及文件MIME类型，即：
'avatar': ('robot.png', open('/Users/apple/Pictures/robot.png', 'rb'), 'image/png'),
比如有些接口上传Excel文件时必须声明文件名和MIME类型，如：
```python
res = request.post(url, files={'upload_file':
        ('data.xlsx',
        open('data.xlsx', 'rb'),
        'application/ms-excel')
    })
```
MIME类型参考：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_types
#### 发送Binary格式数据（单文件/流式上传）
请求方法中的data参数还支持传入一个打开的文件，此时，请求按Binary格式流式上传文件，示例如下：
代码requests_binary_data.py内容
```python
import requests
url = 'https://httpbin.org/post'
res = requests.post(url, data=open('D:\\demo.jpg', 'rb'))
print(res.text)
```
流式上传一般适用于单独的文件上传接口。
### 通用的请求方法
除GET和POST请求外，PUT、DELETE等HTTP请求方法使用requests对应的方法即可，requests中包含的请求方法如下：
- requests.get(url, **kwargs)：发送GET请求
- requests.post(url, **kwargs)：发送POST请求
- requests.put(url, **kwargs)：发送PUT请求
- requests.delete(url, **kwargs)：发送DELETE请求
- requests.head(url, **kwargs)：发送head请求
- requests.options(url, **kwargs)：发送options请求
这些请求方法的参数和用法一致，必选参数为url，其他参数为可选参数，常用参数如下：
- url：字符串格式，参数也可以直接写到url中；
- params：url参数，字典格式；
- data：请求数据，字典或字符串格式或二进制格式；
- headers：请求头，字典格式；
- cookies：字典格式，可以通过携带cookies绕过登录
- json: 字典格式，用于发送JSON格式请求数据；
- files: 字典格式，用于混合表单（form-data）中上传文件；
- auth：Basic Auth授权，数组格式auth=(user,password)
- timeout: 超时时间（防止请求一直没有响应，最长等待时间），数字格式，单位为秒
这些方法都源于一个通用的请求方法`requests.request(method, url, **kwargs)`。这个通用的方法通过必选参数method来指定使用的请求动作。字符串格式，不区分大小写，即requests.get(url)相当于requests.request('get', url)。
因此我们可以用同样结构的数据来组装任何的HTTP请求，示例如下：

> 代码requests_general_method.py内容
```python
import requests

res = requests.request(
    method='post',   # 也可以只写'post',
    url='https://httpbin.org/post',  # 也可以只写'https://httpbin.org/post',
    headers={},
    data={'name': '临渊', 'password': '123456'}
)
print(res.text)
```
请求中也可以根据需求添加其他参数，这一组组键值对参数可以使用一个统一的字典来表示，即：
```python
req = {
    'method': 'post',
    'url': 'https://httpbin.org/post',
    'headers': {},
    'data': {'name': '临渊', 'password': '123456'}
}
```
然后通过**req字典解包，可以将一个字典参数req重新还原为其中的4组参数，因此上例子可以改为：
代码requests_genaral_method2.py内容
```python
import requests

req = {
    'method': 'post',
    'url': 'https://httpbin.org/post',
    'headers: {},
    'data': {'name': '临渊', 'password': '123456'}
    }
res = requests.request(**req)
print(res.text)
```
### 会话保持及默认配置
会话（Session），一般指客户端和服务端的一次连接交互过程。在使用requests.get()等方法时，每次会建立一个新的会话与服务器进行连接。这样不便于保持会话（如登录）状态，如果想要保持会话状态，可以使用同一个会话对象来请求所有接口，示例如下：
> 代码requests_keep_session.py内容
```python
import requests

s = requests.Session()
s.get('http://httpbin.org/cookies/set/sessioncookie/123456789')
r = s.get("http://httpbin.org/cookies")
print(r.text)
```
第一步，使用requests.Session()反复，新建一个会话对象s。

第二步，使用新建的会话对象发送第一个请求（而不是requests），使用方法和requests的请求方法一致。
> 注：此处由于不需要第一个接口的响应内容，因此未使用变量接收响应对象。

第三步，使用同样的会话对象继续发送请求，此时，会自动携带之前请求已设置的Cookies。执行结果如下：
```json
{
  "cookies": {
    "sessioncookie": "123456789"
  }
}
```
会话对象还可以用来设置默认的请求头，超时时间等HTTP默认配置，示例如下：
```python
s = requests.Session()
s.auth = ('user', 'pass')
s.timeout = 10
s.headers={'token1': 'abc'}
res = s.get('http://httpbin.org/headers', headers={'token2': '123'})
print(res.text)
```
以上示例中，通过会话对象，设置了默认的授权、超时时间和默认的请求头。在使用该会话对象发送请求时便可以共享此配置，示例中，两个请求头项都会被携带发送，请求结果如下：
```
{
  "headers": {
    "Accept-Encoding": "identity",
    "Authorization": "Basic dXNlcjpwYXNz",
    "Host": "httpbin.org",
    "Token1": "abc",
    "Token2": "123",
    "X-Amzn-Trace-Id": "Root=1-5e610bfb-7f0b241bd03bd86ff2f10415"
  }
}
```
### 3.1.5  Requests常见问题
在学习完Requests发送请求的基础方法之外，本节带领大家来学习Requests请求的一些同名参数处理、SSL证书验证等问题的处理反复及适配器、Hooks等进阶使用技巧。

1.乱码处理
当res.encoding解码格式和res.apparent_encoding明显编码格式不一致时，便可能出现乱码，如请求百度首页，打印res.text会发现有乱码，重新设置res.encoding为明显编码的格式，再次打印res.text便可以修复乱码。示例如下：
```python
import requests

res = requests.get('https://www.baidu.com/')
print(res.text)  # 有乱码
print('解码格式', res.encoding)  # 解码格式 ISO-8859-1
print('明显编码', res.apparent_encoding)  # 明显编码 utf-8
res.encoding = res.apparent_encoding # 修改解码格式
print(res.text)  # 乱码解决
```

1.同名参数处理
有时候，有些接口的URL参数、表单格式的请求参数或请求头中会出现同名参数，例如，假设接口需要三个参数：name=临渊、age=18、age=30。由于Python的字典中不允许出现重名的key。因此我们不能使用字典格式来构造。此时可以使用列表嵌套元祖的方式来组装，示例如下：

> 代码requests_handle_same_name_params.py内容
```python
import requests
url = 'https://httpbin.org/get'
params = [('name', '临渊'), ('age', '18'), ('age', '30')]
res = requests.get(url, params=params)
print(res.text)
```
请求方法中的其他参数，如data、headers等，如果存在同名变量也可以这样处理。
> 注：由于该接口实际不支持同名参数，因此响应中会只显示一个age的值。

2.关闭SSL证书验证
requests在请求HTTPS接口时，默认验证SSL证书。请求方法中参数verify默认为True，如果想要关闭证书验证，可以设置为False，示例如下：
requests.get('https://www.baidu.com', verify=False)
这种方法，常用于解决请求测试环境接口时遇到的一些SSL证书验证报错问题。

3.关闭自动重定向
当遇到重定向接口，requests默认跟随重定向，返回所重定向接口的响应对象（<Response [200]>），对于一些单点登录后转向的接口，有时我们需要获取原接口响应中的token信息，则需要使用allow_redirects=False关闭自动重定向，使用方法如下：
代码requests_close_redirects.py内容
```python
import requests

res = requests.get('https://httpbin.org/status/302')
print(res.status_code)
print(res.history)
res = requests.get('https://httpbin.org/status/302', allow_redirects=False)
print(res.status_code)
print(res.headers)
```
上例中，第一个请求使用默认自动跟随重定向，因此返回的状态码是最终接口的状态码。可以使用响应对象的history属性查看重定向请求历史。
第二个请求关闭了自动重定向，因此返回的是所请求接口的状态码及响应头，执行结果如下：
```
200
[<Response [302]>, <Response [302]>]
302
{'Date': 'Mon, 02 Mar 2020 13:40:58 GMT', 'Content-Length': '0', 'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'location': '/redirect/1', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true'}
```
res.history是请求的重定向历史，列表格式，其中是每一次重定向请求的响应对象。

4.如何使用代理
在某些场景下，特别是爬虫需求中，通常需要使用代理来发送请求。requests请求方法的proxies参数，支持使用代理来发送请求。对于HTTP和HTTPS，需要分别配置。使用方式如下：
代码requests_with_proxies.py内容
```python
import requests

proxies = {
  "http": "http://10.10.1.10:3128",
  "https": "http://10.10.1.10:1080",
}
requests.get("http://example.org", proxies=proxies)
requests.get("https://httpbin.org", proxies=proxies)
```
请求时，会根据URL中的协议方式来选择使用不同的代理。
> 注：由于示例中配置的代理已经失效，需要读者自行寻找可用的代理地址。

5.请求超时设置
为避免请求长时间没有反应而阻塞其他请求，可以在发送请求时设置超时时间，可以设置请求整体的超时时间，也可是对建立连接和下载请求分别设置超时时间，默认单位是秒，设置方法如下：
代码requests_with_timeout.py内容
```python
import requests

try:
    requests.get('https://github.com', timeout=10)
    requests.get('https://github.com', timeout=(0.1, 0.2))
except requests.exceptions.ConnectTimeout:
    print('请求超时')
else:
    print('请求正常')
```
以上示例，第一个请求中，设置了整体的超时时间为10秒，第二个请求分别对连接时间和下载响应内容时间设置超时时间为0.1秒和0.2秒，如果在超时时间内未完成响应，则抛出超时异常。上例中对异常进行了捕获，并打印了相关信息，else段在未出现异常时执行。

6.如何下载文件
对应资源类接口（如图片链接），想要保持文件，可以直接使用res.content按二进制保存文件即可，示例如下：

> 代码requests_download_file.py内容
```python
import requests

res = requests.get('https://upload.jianshu.io/users/upload_avatars/7575721/5339c9d6-be6b-47cf-87cc-c0517467c6bc.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/240/h/240')
with open('avatar.png', 'wb') as f:
    f.write(res.content)
```
对应较大的文件，可是使用流式下载，示例如下：
代码requests_download_large_file.py内容
```python
`import requests
res = requests.get('https://upload.jianshu.io/users/upload_avatars/7575721/5339c9d6-be6b-47cf-87cc-c0517467c6bc.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/240/h/240')
with open('avatar.png', 'wb') as f:
    for data in res.iter_content(128):  # 按128字节分块保存
        f.write(data)
with open('avatar.png', 'wb') as f:
    for data in res.iter_content(128):  # 按128字节分块保存
        f.wri`te(data)
```
### 3.16  Requests其他使用技巧
1.授权设置
授权是请求身份验证的一些开放协议标准，授权协议很多，包括Basic Auth基础授权，Digist Auth摘要授权，OAuth等。
 1. Basic Auth授权处理
Basic Auth是一种使用用户名及密码来完成的一种授权及身份验证方式，在requests中使用Basic Auth方法非常简单，只要将用户名和密码组合，传入请求方法的auth参数即可，例如github的API支持使用Basic Auth请求，示例如下：

```python
import requests
res = requests.get('https://api.github.com/user', auth=('githab账号', '密码'))
print(res.text)
```

 2. Bearer Token及JWT（JSON Web Token）
Bearer Token是一种身份凭证及授权方式，常见于三方OAuth授权。JWT是一种使用基于JSON开放标准设计的Token，常见于SSO单点等。获取到的Token一般放于请求头的Authorization字段中，格式如下：
```
Authorization: Bearer 具体的token字符串
```

JWT一般改为使用JWT字样（也有些使用Bearer字样），格式如下：
```
Authorization: JWT 具体的token字符串
```

要使用Bearer或JWT授权，只需按照说明获取到Token，按相应格式组装到请求头中使用即可，Demo示例如下：
> 代码requests_with_jwt_token.py内容
```python
import requests
def get_jwt_token(username, password):
    sso_login_url = 'https://sso.***.cn/auth/login'  # 单点登录url
    login_data = {'username': username 'password': password}
    res = requests.post(sso_login_url, data=login_data, allow_redirects=False)
    jwt_token = res.cookies.get('tokenKey')  # 假设返回的token存储于响应Cookies的tokenKey字段
    return jwt_token
def get_info(jwt_token):
    url = '具体要获取信息的接口'
    headers = {'Authorization': 'JWT ' + jwt_token}
    res = requests.get(url, headers=headers)
jwt_token = get_jwt_token('用户名', '密码')
get_info(jwt_token)
```
整个单点登录的流程可以通过抓包获取到token的流转过程，获取到token值，按指定格式放置于请求头中即可完成授权。
> 注：有时res.cookies中并没有包含所有响应头Set-Cookie字段的值，如果通过res.cookies获取不到对应的token字段，可以尝试使用res.headers.get('Set-Cookie')获取到字符串格式的所有Set-Cookie字段的值，然后通过正则匹配或者分割重组为字典格式提取。

 3. OAuth2.0
OAuth2.0一般用于开放平台及三方社交应用授权。OAuth2.0有多种使用场景，一般情况下你要有一个应用（Web服务）及回调接口。用户在你的应用上选择使用三方账号登录时，跳转到三方应用进行授权，授权后跳转到你的回调接口，三方平台会将access_token传递到你的回调接口。
一种是三方平台如GitHub直接给你一个生成一个Bearer token，按Bearer Token的格式放入请求头中即可。
另外一种，如百度开放平台，支持使用用户凭证，即创建应用时生成的客户端id和秘钥（client_id及client_secret）来获取access_token，示例如下：

> 代码requests_with_oauth2.py内容
```python
import requests

url  = 'https://aip.baidubce.com/oauth/2.0/token'
params = {
    'grant_type': 'client_credentials',
    'client_id': 'kPoFYw85FXsnojsy5bB9hu6x',
    'client_secret': 'l7SuGBkDQHkjiTPU3m6NaNddD6SCvDMC[[hzc2]](#_msocom_2) '
}
res = requests.get(url, params=params)
print(res.json().get('access_token'))
```
其他平台token的获取及身份验证方式，可参考平台对应的API文档。

2.预制请求
假设有多个请求需要先准备好，再逐个发送，可以使用requests.Request()对象的prepare()方法生成预制请求对象，然后使用会话的send()方法，发送即可，示例如下：
代码requests_prepare_request.py内容
```python
import requests
s = request.Session()
req1 = requests.Request('GET', 'https://httpbin.org/get').prepare()
req2 = requests.Request('POST', 'https://httpbin.org/post', data={'a':1}).prepare()
s.send(req1)
s.send(req2, headers={'x-test': 'true'})
```
以上示例中，生成了两个预制请求对象req1和req2，然后再分别发送，发送时也支持携带另外的请求头。
预制请求可以将配置请求和发送请求分开，如生产者-消费者模式，生成者负责生成预制请求对象，放入队列中个，多个消费者，从请求中获取预制请求对象，直接发送即可。

3.使用适配器
适配器一般也叫拦截器，用于对匹配到的指定形式的请求做特殊处理。可以直接使用requests.adapters中的HTTPAdapter给定响应参数，也可以继承HTTPAdapter或BaseAdapter自定义处理方式，示例如下：
代码requests_with_adapter.py内容
```python
import requests

s = requests.Session()
a = requests.adapters.HTTPAdapter(max_retries=3)  # 设置最大重试3次
s.mount('http://', a)  # 对该会话所有http://开头的请求使用
```
以上示例中，首先新建了会话对象s，以及适配器对象a，该适配器直接使用了requests自带的HTTPAdapter适配器，斌设置了最大重试次数为3次。然后通过会话对象的mount方法，对该会话所有发送的所有http://形式的请求挂载了该适配器。除requests已经定制好的HTTPAdapter外，也可以自行集成BaseAdapter，编写自己的适配器类。

4.使用响应钩子
Hooks即钩子方法，用于在某个框架固定的某个流程执行是捎带执行（钩上）某个自定义的方法。Requests库只支持一个response的钩子，即在响应返回时可以捎带执行我们自定义的某些方法。可以用于打印一些信息，做一些响应检查或想响应对象中添加额外的信息，示例如下：
代码requests_with_hooks.py内容
```python
import requests

url = 'https://httpbin.org/post'
def verify_res(res, *args, **kwargs):
    print('url', res.url)
    res.status='PASS' if res.status_code == 200 else 'FAIL'
res = requests.get(url, data=data, hooks={'response': verify_res})
print(res.text)
print(res.status)
```
执行结果如下：
```bash
https://httpbin.org/post
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<title>405 Method Not Allowed</title>
<h1>Method Not Allowed</h1>
<p>The method is not allowed for the requested URL.</p>
FAIL
```
以上示例中，“verfiy_res”是我们自定义的方法，第一个参数为响应对象，后面“kwargs”里是请求的一些配置。钩子方法不能返回响应对象以外的有意义值，否则会破坏后面对响应对象的处理。
由于该接口只支持post请求，使用get请求时响应状态码为405（请求方法不被允许），因此响应对象被添加的status的值为FAIL。
## 2.2  请求参数化即数据驱动
之前的请求中，请求的参数是直接写在字符串url或构造的字典中的。但是有时候，某些参数需要从数据文件或其他接口获取，这种把动态变量组装到请求报文里的过程就叫做参数化。
在组装请时，最常见的是组装字符串格式的url及者字典格式的params、data、json、files等参数，一般可以通过Python的字符串格式化及字典的赋值和更新操作来完成。
### 字符串格式化
字符串格式化即提前在字符串中埋设特定的占位符，后面再将对应的变量值填进去。Python中常用的是字符串格式化有%号、format、f-String等方式。
#### 使用%号格式化字符串
在字符串需要填充变量真实值的地方使用占位符（如%s）占位，字符串后使用%按顺序接要传入的变量，多个变量要放到一个元祖中。也可以是使用具名占位符（如%(变量名)s），后接字典，按键值，将变量填入其中，示例如下：
> 代码python_percent_format.py内容
```python
import random

a = random.randint(0,10)
b = random.randint(0,10)
base_url = 'https://httpbin.org'
url = base_url + 'get/?a=%s' % a
print(url)
url = base_url + '/get?a=%s&b=%s' % (a, b)
print(url)
url = base_url + '/get?a=%(a)s&b=%(b)s' % {"b": b, "a": a}
print(url)
```
以上示例中，使用random.randint(1,10)生成了两个随机变量a和b。
第一个url中，将实际变量a的值 9. 以填入%s所在位置。
第二个url中，多个变量传入时，需要放到元祖（小括号）里，按先后顺序填充占位符。
第三个url中，为两个占位符声明了名称，%号后出传入一个字典，按字典键值填充占位符。
打印结果如下：
```bash
https://httpbin.orgget/?a=9
https://httpbin.org/get?a=9&b=5
https://httpbin.org/get?a=9&b=5
```
Python中常用的占位符有：
- %s：字符串形式输出，非str类型会转为其字符串格式输出。
- %d：整数格式输出。
- %f：浮点格式输出。
- %x：十六进制格式输出。
在格式化字符串时还支持指定输出的宽度，如%10s，输出的字符会占据10个字符，默认右对齐（左对齐使用%-10s）。浮点数中还支持指定保留的小数点位数，如%.2f，数字将四色五人保留两位小数点，示例如下：
```python
print('%s' % {'a': 1, 'b': 2})
print('%10s' % 'hello')
print('%d' % 3.0)
print('%.2f' % 1.999)
print('%x' % 16)
```
执行结果为：
```bash
{'a': 1, 'b': 2}
     hello
3
2.00
10
```
第一行字典实际上是字符串格式的"{'a': 1, 'b': 2}，第二行，输出变量占据10个字符，右对齐。第三行，浮点数按整型输出。第四行，浮点数保留两位小数，四舍五入后输出。第五行，数字转为按16进制新式输出。
#### 使用format格式化
format是Python2.6后，字符串自带一种格式化方法。使用占位符{}号来代替%号。{}号中还支持填入数字，填入变量名及填入“:”来完成格式控制，示例如下：
代码python_str_format.py内容
```python
import random
a = random.randint(0,10)
b = random.randint(0,10)
base_url = 'https://httpbin.org'
url = base_url + '/get?a={}&b={}'.format(a, b)
print(url)
url = base_url + '/get?a={0}&b={1}&a={0}'.format(a,b)
print(url)
url = base_url + '/get/?a={a}&b={b}'.format(a=a, b=b)
print(url)
```
第二个url中，通过数字索引，指定要输出的变量，可以多次使用同一变量。
第是哪个url中，使用了具名占位符，按对应参数的值进行输出。
打印结果如下：
```bash
https://httpbin.org/get?a=10&b=0
https://httpbin.org/get?a=10&b=0&a=10
https://httpbin.org/get/?a=10&b=0
```
format语法的{}号中，还支持使用“:”来控制输出格式以及字典列表取值、对象取属性操作。示例如下：
```python
a = 1.333
b = [1,2,3,4]
print('{:.2}'.format(a))
print('{b[0]}'.format(b=b))
```
执行结果为：
```bash
1.3
1
```

#### 使用f-string
f-string是Python3.6后引入的一种新的字符串格式化方式，在字符串引号前添加f或F作为标记，字符串中可以使用“{表达式}”占位符，在实际运行时会对表达式进行求值，示例如下：
```python
import random
a = random.randint(0,10)
b = random.randint(0,10)
base_url = 'https://httpbin.org'
url = f'{base_url}/get?a={a}&b={b}'
print(url)
```
在使用f-String时，要求所引用的变量存在（已经声明过）。运行结果为：
```
https://httpbin.org/get?a=1&b=7
```
除了，直接引用变量外，f-string中还支持各种运算、取值等Python表达式，示例如下：
```python
a = 1.333
b = [1,2,3,4]
print(f'{a+1}')
print(f'{b[0]}')
print(f'{a if a>0 else 0}')
```

> 注：由于f-String是Python3.6之后出现的新特性，某些IDE（如PyCharm社区版）可能会提示错误。此时只要所安装Python是3.6版本以上，都可以正常运行。
### 字典参数的赋值与更新
在组装请求报文时，常常要组装字典格式的params、headers、cookies、data、json、files等参数的数据。在构造字典格式的数据时，可以直接引用变量名来组装数据，也可以通过字典的更新操作，更新其中的数据。
代码python_dict_update.py内容
```python
import uuid

token = str(uuid.uuid1())
url = 'https://httpbin.org/get'
params = {'token': token}
headers = {'item': '123'}
headers.setdefault('token', '123')
headers['token'] = token
headers.update({'item1': '123', 'item2': '123'})
res = requests.get(url, params=params, headers=headers)
print(res.text)
```
以上示例，params中直接引用了获取的token变量，组装了请求。假设原有的headers为{'item': '123'}，并且设置了token的默认值123。我们可以用字典的赋值语句，重新对headers中的token赋值，此时默认值被覆盖。如果有多个值要同时更新，也可以使用字典的update函数实现。运行结果如下：
```bash
{
  "args": {
    "token": "355f669a-611d-11ea-931a-600308996e9c"
  },
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Host": "httpbin.org",
    "Item": "123",
    "Item1": "123",
    "Item2": "123",
    "Token": "355f669a-611d-11ea-931a-600308996e9c",
    "User-Agent": "python-requests/2.22.0",
    "X-Amzn-Trace-Id": "Root=1-5e64b773-210441fca7484886070ae8d7"
  },
  "origin": "111.202.167.8",
  "url": "https://httpbin.org/get?token=355f669a-611d-11ea-931a-600308996e9c"
}
```
### 2.2.2  使用随机数据
在接口测试过程中，对同一个测试点，往往要使用不同的数据来验证。使用可以调试通过的单个的固定数据，则往往会由于测试场景比较单一而不能发现接口的一些潜在问题。使用随机数据则可以使覆盖的场景更加丰富。
另外，有些接口（如，新用户注册）无法反复使用同一数据达到期望的结果，此时也可是使用随机数据。
Python自带的random库、uuid库等提供了一些生成随机数据的方法，常用的方法如下：
- random.random()：随机生成0到1（不包括1）的浮点数。
- random.randint(1,10)：随机生成1到10（不包括10）的整数。
- random.uniform(0.5,5.5)：随机生成0.5到5.5（不包括5.5）的浮点数。
- random.randrange(1,20,2)：随机生成1到20，间隔为2的一个随机数。
- random.shuffle([1,2,3,4,5,6])：随机打乱顺序，生成新的序列。
- random.choice([1,2,3,4,5,6])：随机从序列中选择1个。
- random.sample([1,2,3,4,5,6], 3)：随机从序列中选择3个，生成新的序列。
- uuid.uuid1()：根据时间戳和MAC地址生成36位的唯一编码。
以下示例中演示了一个简单生成随机中文姓名的方法，代码如下：
代码python_random_data.py内容
```python
import random
import string

list1 = ['赵', '钱', '孙', '李', '周', '吴', '郑', '王']
list2 =['志', '玉','明','龙','芳','军','玲', '海']
list3 =['','立','玲','','国','明', '花']
list4 = string.ascii_letters+string.digits
name = random.choice(list1) + random.choice(list2) + random.choice(list3)
password = ''.join(random.sample(list4, 6))
print(name, password)
```
以上示例中使用了Python自带的string库，string.ascii_letters是所有英文字母的集合，string.digits是所有数字字符的集合，password从两者的合集中随机取出6个字符，然后拼接成字符串。
### 2.2.4  使用CSV数据
除了使用随机和模拟数据之外，数据也可以来源于文件，特别是大批量的数据。
CSV（Comma-Separated Values），即逗号分隔值，一种以逗号分隔按行存储的文本文件，类似于Excel单张Sheet表，比Excel更轻量，常用于存储大批量的表格型（矩阵型）数据。
如果CSV中有中文，应以utf-8编码读写，如果要支持Excel查看，应使用utf-8 with bom格式及utf-8-sig格式存储。
#### 基本使用
Python3操作CSV文件使用自带的csv模块即可，csv模块中主要包含用于读取reader和用于写入的writer两种类：
reader = csv.reader(f, delimiter=',')：用来读取数据，reader为生成器，每次读取一行，每行数据为列表格式，可以通过delimiter参数指定分隔符
writer = csv.writer(f)：用来写入数据，按行写入，writer支持writerow(列表)单行写入，和writerows(嵌套列表)批量写入多行，无须手动保存。
当文件中有标题行时，可以使用header=next(reader)先获取到第一行的数据，再进行遍历所有的数据行。
写入时，可以先使用writer.writerow(标题行列表)，写入标题行，再使用writer.writerows(多行数据嵌套列表)，写入多行数据（也可以逐行写入）。
例如，数据文件csv_data.csv：
```csv
name,password
abc,123456
张五,123#456
张#abc123,123456
666,123456
a b,123456
```
读取示例：
代码python_read_csv.py内容
```python
import csv
with open('csv_data.csv', encoding='utf-8') as f:
    reader = csv.reader(f)
    header = next(reader)
    print(header)
    for row in reader:
        print(row)
```
reader必须在文件打开的上下文中使用，否则文件被关闭后reader无法使用，所有的数字被作为字符串，如果要使用数字格式，应使用int()/float()做相应转换。运行结果如下：
```csv
['name', 'password']
['abc', '123456']
['张五', '123#456']
['张#abc123', '123456']
['666', '123456']
['a b', '123456']
```
写入CSV文件使用writer.writerow(列表数据)按行写入即可。也可以使用writer.writerows(嵌套列表数据)批量写入多行，示例如下：
代码python_write_csv.py内容
```python
import csv

header = ['name', 'password', 'status']
data = [
    ['abc', '123456', 'PASS'],
    ['张五', '123#456', 'PASS'],
    ['张#abc123', '123456', 'PASS'],
    ['666', '123456', 'PASS'],
    ['a b', '123456', 'PASS']
]
with open('csv_result.csv', 'w', encoding='utf-8', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(header)
    writer.writerows(data)
```
打开文件时应指定格式为w, 文本写入，不支持wb,二进制写入，当然，也可以使用a/w+/r+
打开文件时，指定不自动添加新行newline='',否则每写入一行就或多一个空行。
如果想写入的文件Excel打开没有乱码，utf-8可以改为utf-8-sig。
运行结果，result.csv内容如下：
```bash
name,password,status
abc,123456,PASS
张五,123#456,PASS
张#abc123,123456,PASS
666,123456,PASS
a b,123456,PASS
```
#### 使用字典格式的数据：DictReader和DictWriter
对于带标题行的CSV数据，我们往往希望每一行得到一个带有变量名的字段格式的数据。此时对于带标题行的CSV文件，可以使用DictReader和DictWriter。
reader=csv.DictReader(f)：直接将标题和每一列数据组装成有序字典（OrderedDict）格式，无须再单独读取标题行。
writer=csv.DictWriter(f, 标题行列表)：写入时可使用writer.writeheader()写入标题，然后使用writer.writerow(字典格式数据行)或write.writerows(多行数据)，读取示例如下：
代码python_read_csv_to_dict.py内容
```python
import csv
with open('data.csv', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        print(row['name'], row['password'])
```
每一行是一个OrderedDict有序字典，可以通过字典取值，方便的获取对应变量的值。
对于带标题行的CSV数据，使用DictWriter写入更加方便，示例如下：
代码python_write_dict_to_csv.py内容
```python
import csv

header = ['name', 'password', 'status']
data = [
    {'name':'abc', 'password':'123456', 'status':'PASS'},
    {'name':'张五', 'password':'123#456', 'status':'PASS'},
    {'name':'张#abc123', 'password':'123456', 'status':'PASS'},
    {'name':'666', 'password':'123456', 'status':'PASS'},
    {'name':'a b', 'password':'123456', 'status':'PASS'}
]
with open('result2.csv', 'w', encoding='utf-8', newline='') as f:
    writer = csv.DictWriter(f, header)
    writer.writeheader()
    writer.writerows(data)
```
写入结果，同result.csv
#### 完整数据驱动请求示例
我们已httpbin.org的post接口示例，使用CSV数据批量发送请求，并将结果写入另一个csv文件，代码如下：
代码requests_ddt_with_csv.py内容
```python
import csv
import requests

def httpbin_post(name, password):
    url = 'https://httpbin.org/post'
    data = {'name': name, 'password': password}
    res = requests.post(url, data=data)
    return 'PASS' if res.status_code == 200 else 'FAIL'
def main():
    data_file = open('data.csv', encoding='utf-8')
    reader = csv.DictReader(data_file)
    header = reader.fieldnames
    result_file = open('result.csv', 'w', encoding='utf-8')
    writer = csv.DictWriter(result_file, header+['result'])
    writer.writeheader()
    for line in reader:
        line['result'] = httpbin_post(line['name'], line['password'])
        writer.writerow(line)
    data_file.close()
    result_file.close()
main()
```
以上示例中，定义了一个函数httpbin_post用于根据不同的参数发送请求，这里只对响应的状态码做了简单判断，并返回PASS或者FAIL。
在main函数中打开两个CSV文件，data_file用于读取数据，result_file用于存取结果。使用DictReader的reader.fieldnames可以获取列表格式的标题行。在结果文件中新增了一个result列，对于每一行OrderedDict格式的数据line，可以直接通过赋值来添加数据，然后使用writer按行写入即可。
### 2.2.5  使用Excel数据
相比CSV，Excel在构造数据时会更加方便，易用性更好。因此小批量的数据也可以使用Excel存放。
Python中常用的操作Excel的三方包有xlrd、xlwt和openpyxl等，xlrd支持读取.xls和.xlsx格式的Excel文件，只支持读取，不支持写入。xlwt只支持写入.xls格式的文件，不支持读取。openpyxl不支持.xls格式，但是支持.xlsx格式的读取写入，并且支持写入公式等，这里讲解openpyxl的一些基本使用方法。
1．安装方法
使用pip安装即可，命令如下：
```bash
$ pip install openpyxl
```

2．读取Excel数据
使用openpyxl读取数据的基本步骤如下：
 1. 加载Excel文件：excel=openpyxl.load_workbook('Excel文件路径')
 2. 选择Sheet工作表：sheet=excel.active获取当前工作表，或sheet=excel.get_sheet_by_name('Sheet1')获取指定表明的工作表。
 3. 按行读取工作表中的数据：for line in sheet.values: ...
假设，数据文件data.xlsx，Sheet1内容如图3.1所示。

图3.1  示例Excel文件data.xlsx，Sheet1数据

读取示例如下：
代码python_read_excel.py内容
```python
import openpyxl

excel = openpyxl.load_workbook('data.xlsx')
sheet = excel.active
for line in sheet.values:
    print(line)
```
上例中，excel是整个工作薄，sheet是当前激活的表（默认为第一张表），sheet.values是一个生成器，遍历每次打印一行数据，执行结果如下：
```bash
('name', 'method', 'url', 'data', 'headers', 'verify', 'result')
('get请求', 'get', 'https://httpbin.org/get?a=1&b=2', None, None, 'res.status_code==200', None)
('post-form', 'post', 'https://httpbin.org/post', 'name=Kevin&age=1', 'Content-Type:x-www-form-urlencoded', "res.status_code==200\nres.json()['form']['name']=='Kevin'\n", None)
('post-json', 'post', 'https://httpbin.org/post', '{"name": "Kevin", "age": 1}', 'Content-Type: application/json, None, None)
```
Sheet对象的一些常用方法如下：
- sheet.max_column：最大（有数据的）列数。
- sheet.max_row：最大（有数据的）行数。
- sheet.iter_rows(min_row=1, min_col=1, max_col=3, max_row=3): 按行迭代指定行、列范围内的数据。
- sheet['A1'].value：获取A1单元格数据。
- sheet.cell(1,1).value：获取第一行第一列单元格数据。
#### 写入Excel数据
写入Excel可以通过赋值直接修改或写入指定单元格，也可以通过sheet.append()在表中追加一整行数据，示例如下：
代码python_write_excel.py内容
```python
import openpyxl

excel = openpyxl.load_workbook('data.xlsx')
sheet = excel.active
sheet['G2'] = 'PASS'
sheet.cell(3,7).value = 'PASS'
new_line = ['post-xml',
          'post',
          'https://httpbin.org/post',
          '<xml>hello</xml>',
          'Content-Type:application/xml',
          'res.json()["data"]=="<xml>hello</xml>"']
sheet.append(new_line)
excel.save("data.xlsx")
```
以上示例中，在G2单元格和第3行第7列写入了PASS,然后在下面追加了一行数据，保存并覆盖了原文件（也可以使用不同的文件名，保存为新文件），执行后，运行结果如图3.2所示。
图3.2 执行后Excel文件data.xlsx,Sheet1数据
#### Excel数据模板解析示例
一种简单的测试框架是使用约定的格式来描述请求数据，然后使用脚本按约定格式解析即可。
如上例中的Excel模板，使用method指定使用的请求方法，url参数可以写在url中，post请求的数据data（原始读取出来为字符串格式）按行分割,再按=号分割组成字典格式，（xml请求不分割）然后根据type类型按不同的方式发送。
verify列可以填写断言，多条断言可以使用多行，断言语句这里直接使用Python的表达式语法来描述，这里约定res代表响应对象，解析时使用eval()函数进行计算。
如果没有断言或者断言都通过，结果为PASS，如果抛出AssertionError断言失败则结果为FAIL，如果断言写错抛出其他异常则结果为ERROR。
实现代码如下：
代码requests_ddt_with_excel.py内容
```python
import openpyxl
import requests

def run_excel(excel_file):
    excel = openpyxl.load_workbook(excel_file)
    sheet = excel.active
    for index, line in enumerate(sheet.values):
        if index == 0:  # 跳过标题行
            continue
        name, method, url, data, headers, verify, *_ = line  # 解包，舍弃第7列以后的值
        # 处理请求头
        if headers:
            headers = {line.split(':')[0].strip(): line.split(':')[1].strip()
                       for line in headers.split('\n')}
        # 处理请求数据，为支持中文数据，需要将文本按utf-8编码为bytes
        if data is not None:
            data = data.encode('utf-8')
        # 发送请求
        print(f'请求第{index + 1}行接口: {name}')
        res = requests.request(method, url, data=data, headers=headers)
        print('响应：', res.text)
        # 处理断言
        result = 'PASS'
        if verify:
            lines = verify.split('\n')  # 按行分割转为列表
            for line in lines:
                if not line:  # 跳过空行
                    continue
                try:
                    assert eval(line)  # 使用eval()来计算表达式的值
                except AssertionError:
                    print("断言出错")
                    result = "FAIL"
                    break
                except Exception as ex:
                    print("断言异常：", ex)
                    result = "ERROR"
                    break
                finally:
                    print('执行断言：', line, '结果：', result)
        sheet.cell(index + 1, 7).value = result  # 在当前行第7列写入结果
    excel.save(excel_file)  # 保存并覆盖原文件
if __name__ == '__main__':
    run_excel('data.xlsx')
```
以上代码中，`name, method, url, data, headers, verify, *_ = line`使用了列表或元祖的解包，前面五个变量分别赋值给name, method, url, data,headers及verify，后面的变量舍弃。
运行结果如下：
```bash
`请求第2行接口: get请求
响应： {
  "args": {
    "a": "1",
    "b": "2"
  },
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.27.1",
    "X-Amzn-Trace-Id": "Root=1-622f3964-5c6543683a50d4d70c70b00d"
  },
  "origin": "36.110.228.100",
  "url": "https://httpbin.org/get?a=1&b=2"
}
执行断言： res.status_code==200 结果： PASS
headers Content-Type: application/x-www-form-urlencoded
请求第3行接口: post-form
响应： {
  "args": {},
  "data": "",
  "files": {},
  "form": {
    "age": "1",
    "name": "Kevin"
  },
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Content-Length": "16",
    "Content-Type": "application/x-www-form-urlencoded",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.27.1",
    "X-Amzn-Trace-Id": "Root=1-622f3966-74b721431d9ed59b304e1aff"
  },
  "json": null,
  "origin": "36.110.228.100",
  "url": "https://httpbin.org/post"
}
执行断言： res.status_code==200 结果： PASS
执行 res.json()['form']['name']=='Kevin'
执行断言： res.json()['form']['name']=='Kevin' 结果： PASS
headers Content-Type: application/json
请求第4行接口: post-json
响应： {
  "args": {},
  "data": "{\"name\": \"Kevin\", \"age\": 1}",
  "files": {},
  "form": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Content-Length": "27",
    "Content-Type": "application/json",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.27.1",
    "X-Amzn-Trace-Id": "Root=1-622f3967-014e39bc25353c3b57df85f3"
  },
  "json": {
    "age": 1,
    "name": "Kevin"
  },
  "origin": "36.110.228.100",
  "url": "https://httpbin.org/post"
}
headers Content-Type: application/xml
请求第5行接口: post-xml
响应： {
  "args": {},
  "data": "<xml>hello</xml>",
  "files": {},
  "form": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Content-Length": "16",
    "Content-Type": "application/xml",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.27.1",
    "X-Amzn-Trace-Id": "Root=1-622f3968-1cc6570a494a21d279491505"
  },
  "json": null,
  "origin": "36.110.228.100",
  "url": "https://httpbin.org/post"
}
执行断言： res.json()["data"]=="<xml>hello</xml>" 结果： PASS`
```
### 2.2.6  使用JSON数据
JSON(JavaScript Object Notation)，即JavaScript对象标记。是一种通用的轻量级的数据交换格式。在Python中，JSON本质上是符合JSON格式的字符串（str类型），即JSON字符串。
#### 序列化和反序列化
序列化和反序列化时编程中的两个基本概念，指内存中的数据结构与可传输、存储类型之间的相互转换。
- 序列化：内存对象转换为文本或文件
- 反序列化：文本文件转换为内存对象
程序中的对象，如Python中的字典、列表、函数、类等，都是存在内存中的，一旦断电就会消失，不方便传递或存储，所以我们需要将内存中的对象转化为文本或者文件格式，来满足传输和持久化（存储）需求。
HTTP协议是超文本传输协议，是通过文本或二进制进行传输的，所以我们发送的请求要转化成文本进行传输，收到的响应也是文本格式，如果是JSON，一般还需要将文本格式重新转化为对象。
#### JSON与Python字典的相互转换
JSON字符串中支持Object对象、Array数组、String字符串、Number数字、true/false布尔值、null空值6中数据类型，并支持层次嵌套。Python中的字典和JSON字符串中描述的数据类型一一对应，对应关系如表3.1所示。
表3.1 JSON字符串与Python的对应

|JSON字符串|Python|
|---|---|
|Object {...}|字典 {...}|
|Array [...]|列表 [...]|
|String "..."|字符串 '...' 或 "..."|
|Number 1.5或3|浮点型或整型 1.5或3|
|true或false|True或False|
|null|None|
JSON格式较为严格，和Python字典格式略有不同：
- 字典中的引号支持单引号和双引号，JSON格式只支持双引号。
- 字典中的True/False首字母大写，JSON格式为true/false。
- 字典中的空值为None, JSON格式为null。
- 字典中可以使用#好注释，JSON中不允许使用任何形式的注释。
- 字典列表最后一项后可以有逗号，JSON数组最后一项后不可以有逗号。
作为一种标准格式的字符串，JSON方便在不同系统中进行数据交换，方便进进行传输和存储，却不方便从整段字符串中提取响应的字段对应的值。
而字典作为内存中的一种数据结构，可以很方便的对其中的数据进行提取或添加等操作。因此我们常常需要在JSON字符串和字典之间相互转换。
在接口请求中常用的转换如下：
 1. 使用字典格式构造请求数据
 2. 转为JSON字符串发送请求
 3. 服务端解析处理
 4. 返回JSON字符串格式的响应数据
 5. 转为字典格式提取相应的字段并断言
Python自带的json库提供JSON字符或JSON文件对象和字典之间的相互转换，主要方法如下：
- json.loads(JSON字符串)/json.load(JSON文件对象)：JSON字符串/文件转字典
- json.dumps(字典)、json.dump(字典，文件对象)：字典转JSON字符串/文件
使用示例如下：

> 代码python_load_dump_json.py内容
```python
import json
data = {
    'name': '临渊',
    'age': 18,
    'on_site': True,
    'favorite': None
}
# dict -->  JSON
data_str = json.dumps(data)
print('字典转JSON字符串', type(data_str), data_str)
# JSON --> dict
data_dict = json.loads(data_str)
print('JSON字符串转回字典', data_dict)
# dict --> JSON文件
with open('data.json', 'w', encoding='utf-8') as f:
    json.dump(data, f)
# JSON文件 --> dict
with open('data.json', 'r', encoding='utf-8') as f:
    data_dict = json.load(f)
print('JSON文件转回字典', data_dict)
```
运行结果如下：
字典转JSON字符串 <class 'str'> {"name": "\u4e34\u6e0a", "age": 18, "on_site": true, "favorite": null}
JSON字符串转回字典 {'name': '临渊', 'age': 18, 'on_site': True, 'favorite': None}
JSON文件转回字典 {'name': '临渊', 'age': 18, 'on_site': True, 'favorite': None}
生成的data.json文件内容如下：
```json
{"name": "\u4e34\u6e0a", "age": 18, "on_site": true, "favorite": null}
```
在使用json.dumps()将字典转为JSON字符串时，默认为确保ASCII码已方便HTTP传输会将中文进行转换，同时默认使用单行格式。如果想要更清晰的查看JSON字符串结果，可以使用ensure_ascii=False不进行转换，使用indent=2空2格缩进显示，sort_keys=True按key排序输出，示例如下：
代码python_dumps_json_with_indent.py内容
```python
import json

data = {
    'name': '临渊',
    'age': 18,
    'on_site': True,
    'favorite': None
}
data_str = json.dumps(data, ensure_ascii=False, indent=2, sort_keys=True)
print(data_str)
```
输出格式如下：
```json
{
  "age": 18,
  "favorite": null,
  "name": "临渊",
  "on_site": true
}
```
#### JSON数据模板解析示例
相较与CSV和Excel，JSON文件非常适合用于描述多层级的树形结构数据，而requests.request()方法的参数就可以通过JSON文件描述。
requests.request()方法常用参数如下：
- method：请求方法，必选，字符串格式，如'GET'，大小写均可。
- url：请求URL，必选，字符串格式。
- params：URL参数，非必选，字典（或嵌套列表）。
- heardes：请求头参数，非必选，字典（或嵌套列表）。
- cookies：请求Cookies，非必选，字典（或嵌套列表）。
- data：请求数据，非必选，字典（或嵌套列表），字符串或打开的文件。
- json：按JSON格式发送的请求数据，非必选，字典（或嵌套列表）。
- files：按Multipart/formdata格式发送的数据，非必选，字典（或嵌套列表）。
- timeout：超时时间
通用请求方法requests.request()的所有参数可以用一个字典来配置，然后通过字典解包，放置在请求中。而JSON由于和字典非常相似，不仅快速转换为字典，还方便进行存储和传输。因此可以将请求字典配置放置到一个JSON文件中。
同时为了节省空间，我们可以在JSON文件中把多个Object（对应Python字典）放置到Array里（对应Python列表）。示例data.json文件内容如下：
```json
[
    {
        "url": "https://httpbin.org/get",
        "method":"get",
        "params": {
            "a": 1,
            "b": 2
        }
    },
    {
        "url": "https://httpbin.org/post",
        "method":"post",
        "data":{
            "name":"Kevin",
            "age":21
        }
    }
]
```
数据文件中，每一个Object中的字段对应requests.request请求方法的参数，必须包含url及method。
对于以上约定的格式，我们只需要编写一个脚本，打开JSON文件，转为列表格式，遍历每一个请求配置，然后通过字典解包放置到requests.request()方法中发送即可，代码如下：
代码requests_ddt_with_json.py内容
```python
import json
import requests
with open('data.json', encoding='utf-8') as f:
    req_list = json.load(f)
for req in req_list:
    res = requests.request(**req)  # 字典拆包
    print(res.text)
```
读者也可以根据需求补充断言描述、变量提取描述及公共配置等，并使用requests的会话保持来保持请求的状态。
### 2.2.7  使用YAML数据
YAML（YAML Ain't Markup Language）即一种反标记（XML）语言。强调数据为中心，而非标记。YAML大小写敏感，使用缩进代表层级关系。
YAML兼容JSON格式，简洁，强大，灵活，可以很方便的构造层级数据并快速转为Python中的字典。
YAML中支持对象Object(对应Python中的字典), 数组Array(对应Python中的列表)以及常量（字符串、数字（int/float），true/false/null）。
相比于JSON格式，YAML免除了双引号，逗号，大括号，中括号等，（当然也支持原始的JSON格式），并且支持注释，类型转换，跨行，锚点，引用及插入等等。
#### 基本格式
- 对象：使用key: value表示，冒号后面有一个空格，也可以是使用{key: value}（flow流格式）或{"key": "value"}表示
- 数组：使用- value表示，-后面有一个空格，每项一行，也可以使用[value1,value2,value3,...] （flow流格式）或["value1", "value2", "value3", ...]
- 字符串：abc或"abc"
- 数字：123或123.45
- true/false：true/false,TRUE/FALSE,True/False或on/off, ON/OFF, On/Off
- null: null,NULL, Null或~
示例文件demo.yaml如下：
```yaml
# 注释：示例yaml文件
name: Cactus
age: 18
skills:
  -
    - Python
    - 3
  -
    - Java
    - 5
has_blog: true
gf: ~
```
相当于以下JSON格式：
```json
{
  "name": "Cactus",
  "age": 18,
  "skills": [
    [
      "Python",
      3
    ],
    [
      "Java",
      5
    ]
  ],
  "has_blog": true,
  "gf": null
}
```
#### 强制类型转换
在Yaml文件中，直接书写的整数会转为int格式。使用!!str，!!float等可以将默认类型转为指定类型，示例如下：
demo2.yaml内容：
```yaml
- !!float 3
- !!str 4
- !!str true
```
对应JSON格式
```json
[
  3.0,
  "4",
  "true"
]
```
#### 多行文本及拼接
Yaml中以下两个字符可以用于拼接多行文本：
- | 保留多行文本（保留换行符）
- > 将多行拼接为一行

示例，demo3.yaml内容如下：
```yaml
a: |
  我
  喜欢你
b: >
  我
  不喜欢你
  才怪
```
对应JSON格式为：
```json
{
  "a": "我\n喜欢你\n",
  "b": "我 不喜欢你 才怪"
}
```
#### 锚点，引用及插入
在-或:后加上&锚点名为当前字段建立锚点，下面可使用*锚点名引用锚点，或使用`<<: *`锚点名直接将锚点数据插入到当前的数据中，demo4.yaml示例如下：
```yaml
users:
  - &zs
    name: 张三
    password: !!str 123456
  - &ls
    name: 李四
    password: abcdefg
case1:
  login: *zs
case2:
  user:
    <<: *ls
    age: 20
```
对应JSON格式为：
```json
{
  "users": [
    {
      "name": "张三",
      "password": "123456"
    },
    {
      "name": "李四",
      "password": "abcdefg"
    }
  ],
  "case1": {
    "login": {
      "name": "张三",
      "password": "123456"
    }
  },
  "case2": {
    "user": {
      "name": "李四",
      "password": "abcdefg",
      "age": 20
    }
  }
}
```
#### Python操作YAML文件及字符串
需要安装pyyaml，安装命令为：
```bash
$ pip install pyyaml
```
和JSON文件类似，yaml也提供load和dump两种方法。
- yaml.load()或yaml.safe_load(YAML字符串或文件句柄)：yaml -> 字典，如yaml中有中文，需要使用 字符串.encode('utf-8')或打开文件时指定encoding='utf-8'。
- yaml.dump(字典)：默认为flow流格式，即字典{b': {'c': 3, 'd': 4}}，会被转为b: {c: 3, d: 4}形式，可以使用default_flow_style=False关闭流模式。
注：由于yaml.load()支持原生Python对象，不安全，建议使用yaml.safe_load()。
示例1：yaml字符串转字典。
代码python_load_yaml.py内容
```python
import yaml
yaml_str = '''
name: Cactus
age: 18
skills:
  -
    - Python
    - 3
  -
    - Java
    - 5
has_blog: true
gf: ~
'''
print(yaml.safe_load(yaml_str))
```
打印结果如下：
```bash
{'name': 'Cactus', 'age': 18, 'skills': [['Python', 3], ['Java', 5]], 'has_blog': True, 'gf': None}
```
> 注：如果有中文，可以使用yaml.load(yaml_str.encoding('utf-8))。

示例2：yaml文件转字典

> 代码python_load_yaml_file.py内容
```python
import yaml
with open('demo.yaml', encoding='utf-8') as f:   # demo.yaml内容同上例yaml字符串
    print(yaml.safe_load(f))
打印结果同上例。
示例3：字典 -> yaml字符串或文件。
代码python_dump_yaml_file.py内容
import yaml
dict_var = {'name': 'Cactus', 'age': 18, 'skills': [['Python', 3], ['Java', 5]], 'has_blog': True, 'gf': None}
print(yaml.dump(dict_var,))  # 转为字符串，使用默认flow流格式
with open('demo5.yaml', 'w', encoding='utf-8') as f:
    yaml.dump(dict_var, f, default_flow_style=False)  # 写入文件，不是用flow流格式
```
打印内容为：
```yaml
age: 18
gf: null
has_blog: true
name: Cactus
skills:
- [Python, 3]
- [Java, 5]
demo5.yaml文件内容如下：
age: 18
gf: null
has_blog: true
name: Cactus
skills:
-
  - Python
  - 3
-
  - Java
  - 5
```
###  使用MySQL数据
在功能、接口测试中常常需要通过数据库的操作，来准备数据、检测环境及核对功能、接口的数据库操作是否正确。在自动化测试中，就需要我们用代码连接数据库自动完成数据准备、环境检查及数据库断言的功能。
常见的数据库类型及需要的Python库如下：
- SQLite数据库操作：Python自带sqlite3
- MySQL数据库操作：三方库PyMySQL
- PostgreSQL数据库操作：三方库Psycopg2
- Oracle数据库操作：三方库cx_Oracle
- Redis操作：三方库Redis
- MongoDB操作：三方库PyMongo
- HBase数据库操作：三方库hbase
- Elasticsearch引擎操作：三方库elasticsearch
- Memcached缓存操作：三方库python-memcached
使用Python操作MySQL数据库这里我们需要用到三方库PyMySQL，安装方法：

```bash
$ pip install PyMySQL
```
数据库操作步骤为：
 1. 建立数据库连接：conn = pymysql.connect()
 2. 从连接建立操作游标：cur = conn.cursor()
 3. 使用游标执行sql（读/写）：cur.execute(sql)
 4. 获取结果（读）/ 提交更改（写）： cur.fetchall()/conn.commit()
 5. 关闭游标及连接：cur.close();conn.close()
游标是指向数据缓冲区的一个变量，可以逐条的访问数据库执行结果集。PyMySQL中需要通过游标来执行sql和获取结果。
#### 基本使用
代码python_operate_mysql.py内容
```python
import pymysql
# 1. 建立连接
conn = pymysql.connect(host='127.0.0.1',
                    port=3306,
                    user='root',
                    passwd='123456',   # password也可以
                    db='api_test',
                    charset='utf8')   # 如果查询有中文需要指定数据库编码       
# 2. 从连接建立游标（有了游标才能操作数据库）
cur = conn.cursor()
# 3. 查询数据库（读）
cur.execute("select * from user where name='张三'")
# 4. 获取查询结果
result = cur.fetchall()
print(result)
# 3. 更改数据库（写）
cur.execute("delete from user where name='李四'")
# 4. 提交更改
conn.commit()  # 注意是用的conn不是cur
# 5. 关闭游标及连接
cur.close()
conn.close()
```
#### 数据库查询操作
使用cur.execute(), 执行数据库查询后无返回的是影响的行数，而非查询结果。我们要使用cur.fetchone()/cur.fetchmany()/cur.fetchall()来获取查询结果
- cur.fetchone()：获取一条数据（同时获取的数据会从结果集删除），返回元祖cur.fetchmany(3)：获取多条数据，返回嵌套元祖(('张三','123456'),('李四','123456'),("王五","123456"))
- cur.fetchall()：获取所有数据，返回嵌套元祖，(('张三','123456'),)
> 注： 获取完数据后，数据会从数据集中删除，再次获取获取不到，如：

```python
cur.execute(select * from user where name='张三')
print(cur.fetchone()) # 结果： ('张三','123456')
print(cur.fetchone()) # 结果：None
print(cur.fetchall()) # 结果：()
```

所以我们需要重复使用查询结果时，需要将查询结果赋给某个变量
```

```python
cur.execute(select * from user where name='张三')
result = cur.fetchall()
print(result)  # 结果： ('张三','123456')
print(result)  # 结果： ('张三','123456')
```
#### 数据修改操作
执行修改数据库的操作后不立即生效，使用连接conn.commit()提交后才生效，支持事物及回滚
```python
try:
    cur.execute("insert into user (name,password) values ('张三', '123456')")
    cur.execute("insert into user (name, passwd) values ('李四'), '123456'") # 此处sql出错
    conn.commit()  # 使用连接提交所有更改
except Exception as e:
    conn.rollback()  # 回滚所有更改（注意用的是conn)
    print(str(e))
```
#### 数据库操作封装
代码db_helper.py内容
```python
import pymysql
# 获取连接方法
class DB(object)
    def get_conn(self):
        self.conn = pymysql.connect(host='127.0.0.1',
                           port=3306,
                           user='test',
                           passwd='123456', 
                           db='api_test',
                           charset='utf8‘# 如果查询有中文，需要指定测试集编码
                           autocommit=True  # 使用autocommit
                           )
       self.cur = self.conn.cursor(pymysql.cursors.DictCursor)  # 使用字典类型的查询结果

# 封装数据库查询操作
def query (self, sql):
    self.cur.execute(sql)  # 执行sql
    result = cur.fetchall()  # 获取所有查询结果, 字典格式
	return result  # 返回结果
def execute(self, sql):
    try:
        cur.execute(sql)  # 执行sql
	except Exception as e:
        conn.rollback()  # 回滚
def close(self):
    self.cur.close()  # 关闭游标
    self.conn.close()  # 关闭连接
```

使用方法如下：
```python
from db import DB

db1 = DB()
print(db1.query(“select * from user where name=‘张三’;”）
print(db.change(“insert into user (‘name’,’passwd’) values (‘张四’,’123456);”)
```
## 2.3  响应解析及断言
### 2.3.1  响应对象及响应断言
Requests请求方法返回响应对象，前面的例子中res即为我们获取到的响应对象，我们打印的res.text为响应对象的字符串格式信息。
#### 响应对象
Requests响应对象常用属性及方法如下：
表3.3  requests响应对象属性及方法

|属性/方法|说明|
|---|---|
|res.status_code|响应的HTTP状态码|
|res.reason|响应的状态码含义|
|res.text|响应的文本格式，按req.encoding解码|
|res.content|响应的二进制格式|
|res.encoding|解码格式，可以通过修改req.encoding来解决一部分中文乱码问题|
|res.apparent_encoding|真实编码，由chardet库提供的明显编码|
|res.headers|响应头，类似字典格式|
|res.cookies|响应的cookies对象,类似字典格式|
|res.json()|将JSON格式的响应数据转为字典，如果响应数据不是合法的JSON格式会报错。|
Requests库会将响应的二进制数据自动编码成文本格式，默认使用res.encoding指定的解码格式。res.apparent_encoding是根据响应内容通过chardet库识别出来的真实格式，当两者不一致时会有乱码现象。
#### 响应断言
断言指期望结果和实际结果的对比。在自动化测试中，脚本不仅要自动执行各个测试步骤，还要完成步骤实际结果与期望结果的比对。在接口测试过程中响应即是我们拿到的步骤结果，我们需要根据业务需求添加断言。常用的断言操作有，状态码断言、响应内容包含某个字符串、JSON响应断言等。
在Python中，可以使用assert跟Python表达式进行断言，示例如下：
代码requests_assert_response.py内容
```python
import requests
import re

res = requests.get('https://httpbin.org/get?name=Kevin&age=12')
print(res.text)
assert 200 == res.status_code  # 断言状态码
assert 'Kevin' in res.text  # 断言包含特定文本
assert re.findall('Kevin', res.text)  # 断言正则匹配结果不为空
res_dict = res.json()  # 转为字典
assert 'https://httpbin.org/get' in res_dict.get('url')  # 断言JSON响应中的url字段
assert res_dict.get('args') == {"name": "Kevin", "age": "12"}
assert res_dict.get('args').get('gender') is None  # True/False/None通常用is判断
```
Python表达式的使用非常灵活，只要表达式结果为真，断言即视为通过，在Python中，False、None、0、'0'、空字符串 、空列表、空集合、空字典都被视为假值，其他则被视为真值。
Python表达式中True、False、None值的判断一般用is或is not判断，而不用“\==”。
Python的相等判断除了支持字符串或数字相等判断外，还支持列表、字典等容器类型的相等判断，如：`{"name": "Kevin", "age": "12"}=={"age": "12", "name": "Kevin"}`。
运行时如果断言通过，不会有任何表示。而断言失败则会抛出AssertionError异常。
> 注：URL参数及Form格式传入的数字都会转为字符串形式，断言时请注意。
### 2.3.2  JSON格式响应解析
在获取到响应对象时，我们常常要从响应数据中提取出对应的字段值来进行断言或关联操作。如果是JSON格式的响应数据，可以通过响应对象的json()方法将响应数据转为字典格式。相较于字符串格式的响应文本，字典格式更方便变量提取等操作。
字典有两种取值方式，字典[key]或者字典.get(key,默认值)，第一种方式如果key不存在会报错，第二种如果key不存在可以设置默认值，未指定时默认为None，因此建议使用第二种。如果有多层嵌套，按照字典及列表的取值方法层层取值。
代码parse_json_response.py内容
```python
import requests

res = requests.get('https://httpbin.org/get')
res_dict = res.json()   # 将JSON格式响应转为字典
res_url = res_dict.get('url')
res_headers_host = res_dict.get('headers',{}).get('Host')
print(f'响应数据中的url字段数据为：{res_url}')
print(f'响应数据中headers字段中的Host字段数据为：{res_headers_host}')
```
运行查看提取到的变量的打印结果：
响应数据中的url字段数据为：https://httpbin.org/get
响应数据中headers字段中的Host字段数据为：httpbin.org

### 2.3.3  XML响应解析
XML是一种常用的数据传输格式。XML由相互嵌套的节点组成。示例如下：
```python
xml = '''
<bookstore>
    <book category="COOKING">
        <title lang="en">Everyday Italian</title>
        <author>Giada De Laurentiis</author>
        <year>2005</year>
        <price>30.00</price>
    </book>
    <book category="WEB">
        <title lang="en">Learning XML</title>
        <author>Erik T. Ray</author>
        <year>2003</year>
        <price>39.95</price>
    </book>
</bookstore>'''
```
#### XML/HTML主要概念
- 节点：节点是XML的基本组成部分，包含开始标签<tag>到结束标签</tag>中的所有内容。
- 标签(tag)：<>中的名称称为标签名。
- 属性：在开始标签中可以包含多个属性，如category="COOKING" category为属性 COOKING为属性值。
- 文本：节点如果没有子节点，开始标签和结束标签的字符串被称为该节点的文本。
节点具有有上下级关系，其中，根节点指XML/最外层的元素节点。元素的外层元素称为该元素的父节点，元素的下一级元素称为其子节点。并列的元素称为同级节点（拥有相同的父节点）。
#### 使用ElementTree解析XML
Python自带的xml.etree库中的ElementTree方法可以解析XML及HTML格式的数据，同时使用XPath查找节点。主要步骤为：
第一步：实例化元素树（ElementTree）得到根节点。
```python
from xml.etree import ElementTree
bookstore= ElementTree.fromstring(xml)
```
第二步：使用.find()或.findall()查找一个或多个节点。
find()和findall()方法中支持试用贴，部分XPath语法来查找节点，支持的XPath语法如下表3.2所示。
表3.2 xml.etree.ElementTree支持的XPath语法

|语句|说明|示例|示例解释|
|---|---|---|---|
|tag|选择下级指定标签的节点|book|选择标签为book的节点|
|*|选择任意标签的节点|book/*|选择book节点下的任意节点|
|.|选择当前节点|./book|选择当前节点下的book节点|
|..|选择上级节点|./book/..|选择book的上级节点（本节点）|
|//|选择任意路径下节点|.//title|选择任意级路径下的title节点|
|[position]|选择指定位置的节点，索引从1开始，最后一用last()表示|./book[2]|选择第2个book节点|
|[@attrib]|选择带有指定属性的节点|.//book[@category]|选择带有category属性的book节点|
|[@attrib='value']|选择指定属性值为value的节点|.//title[@lang="en"]|选择lang属性为en的title节点|
|[tag]|选择具有指定子节点的节点|.//book[title]|选择具有title子节点的book节点|
|[tag="text"]|选择指定子节点文本为text的节点|.//book[title="Everyday Italian"]|选择子标签title文本为Everyday Italian的book节点|
|[][]|多条件筛选|.//book[@category][ title]|选择包含category属性和title子节点的book节点|
find()方法返回节点对象，可以通过.tag或其标签名，通过.text获取其文本，通过.attrib获取其属性字典，也可以继续使用.find()或.findall()继续查找下级子元素，使用示例如下：

> 代码parse_xml_data.py内容
```python
from xml.etree import ElementTree

xml = '''<bookstore>
    <book category="COOKING">
        <title lang="en">Everyday Italian</title>
        <author>Giada De Laurentiis</author>
        <year>2005</year>
        <price>30.00</price>
    </book>
    <book category="WEB">
        <title lang="en">Learning XML</title>
        <author>Erik T. Ray</author>
        <year>2003</year>
        <price>39.95</price>
    </book>
</bookstore>'''
bookstroe = ElementTree.fromstring(xml)
print(bookstroe.find('.').tag)
book_children = bookstore.findall('./book[1]/*')
for node in book_children:
    print(node.tag)
print(bookstroe.find('./book[last()]').find('title').text)
print(bookstroe.find('book[2]').attrib)
print(bookstore.find('.//book[@category][title]'))
```
第一个打印了当前的标签名。
第二个获取了第一个book节点的所有子节点，并遍历打印其标签名。
第三个获取最后一个book节点下的title标签的文本。
第四个输出第二个book节点的属性字典。
第五个输出包含category属性和title子节点的book节点对象。
打印结果如下：
```bash
bookstore
title
author
year
price
Learning XML
{'category': 'WEB'}
<Element 'book' at 0x108782d18>
```
### 2.3.4  HTML响应解析
某些情况下，接口会以HTML网页的形式返回，我们需要从网页中提取某些信息。解析HTML常用的是三方lxml库或者BeautifulSoup4+lxml解析。
安装lxml及beautifulsoup4
```bash
$ pip install lxml
$ pip install beautifulsoup4
```
#### 使用lxml
lxml支持HTML及XML，解析速度快，兼容性强。使用方式和ElementTree比较像。
第一步：使用etree.HTML()实例化得到根节点，实例化时会自动补全HTML代码。
代码parse_html_data_with_lxml.py内容
```python
from lxml import etree
html = '''
<div id="content">
    <ul>
        <li id="top_001" class="item">肖申克的救赎<li>
        <li id="top_001" class="item">霸王别姬</li>
        <li id="top_002" class="item">阿甘正传</li>
    </ul>
</div>
'''
root = etree.HTML(html)
```
第二步：使用root.xpath()查找节点。
不同于xml.etree.ElementTree中只支持部分的XPath语法，root.xpath()中支持使用完整的XPath语法，路径不需要使用“.”开始，root.xpath()方法返回查找到的所有节点列表，示例如下：
- root.xpath('/html/body/div')：绝对路径查找
- root.xpath('//ul/li[2]') ：相对路径，结合索引
- root.xpath('//div[@id="content"]')：结合属性查找
- root.xpath('//li[@id="top_001" and @class="item"]')：多条件查找
- root.xpath('//li[text()="阿甘正传"]')：使用text()函数根据元素文本查找
- root.xpath('//li[contains(text(), "阿甘")]')：使用contains函数查找文本包含
- root.xpath('//li[1]/following-sibling::li')：使用XPath的轴方法获取后面所有的同级元素
如果想要获取节点是属性或文本等，可以从返回的节点列表中取出节点，并使用.tag、.text或.attrib获取节点的标签、文本或属性字典，也可以直接在XPath语句中使用/@attribute或/text来获取属性，示例如下：
```python
div = root.xpath('//div')[0]
print(div.attrib)
print(root.xpath('//div/@id'))
print(root.xpath('//ul/li[last()]/text()'))
```
由于root.xpath()方法返回节点列表，这里去第一个元素，并打印其属性字典。第三行直接使用XPath表达式取相应节点的id属性，返回属性列表。第四行使用XPath表达式text()函数取节点的文本，返回文本列表，打印结果如下：
```bash
{'id': 'content'}
['content']
['阿甘正传']
```
#### 使用BeautifulSoup4
使用BeatifulSoup4结合lxml解析网页的示例如下：
BeautifulSoup4使用步骤如下：
 1. 使用请求得到的HTML实例化一个soup对象
soup = BeautifulSoup(html, 'lxml')
实例化soup对象时，可以指定使用的解析库。可用的解析库可以是Python自带的html.parser、三方库lxml或者html5lib。相比较来说，lxml解析速度快，文档容错能力强，同时支持HTML和XML。因此推荐使用lxml解析器。
 2. 查找节点
使用soup查找节点一般根据标签名及属性组合查找，也可以通过文本查找。常见的查找方法有：
- soup.find()：根据标签名，属性或文本查找节点，返回第一个满足条件的节点。
- soup.find_all()：根据标签名，属性或文本查找节点，返回所有满足条件的节点列表。
- soup.select()：使用CSS Selector语法查找节点，返回所有满足条件的节点列表。
- soup.find()或soup.find_all()可以根据标签名、属性或文本进行组合查找节点，示例如下：
- soup.find('a')  #  查找第一个a标签节点
- soup.find('a', attrs={'href': 'https://movie.douban.com'})  # 查找第一个指定href属性的a节点
- soup.find('div', id='content')  # id和class属性可以简写为id=''及class_=''，注意class多一个下划线
- soup.find('a', text='电影')  # 查找第一个文本“电影”的a节点
- soup.find('a', text=re.complie('电.*')  # 文本查找支持使用正则表达式
- soup.find('div', id='content').find_all('li')  # 支持链式查找下级节点
- soup.select('div#content')  # 使用CSS Selector查找，同soup.find_all('div', id="content")

对于使用find()方法查找的节点，可以使用.text输出其文本、使用.attrs输出其属性字典，或继续使用.find()或.find_all()查找下级元素。
#### 使用requests结合BeautifulSoup4爬取豆瓣电影Top250
第一步：使用requests请求网页https://movie.douban.com/top250/，得到网页HTML，结构如图3.2所示。
图3.2 豆瓣电影Top250

第二步：先使用find()找到id为content的div节点，然后再使用find_all()查找到所有li标签。遍历所有li标签，向下查找div为info节点下的a标签，继续向取span为title的标签，并输出其文本。
第三步：由于每页仅显示25个结果，请求中可以添加参数start，来取下一页结果，循环10次即全部结果，代码如下：
代码crawl_douban_top250_movies.py内容
```python
import requests
from bs4 import BeautifulSoup
headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36"}
for start in range(0, 250, 25):
    html = requests.get(f'https://movie.douban.com/top250/?start={start}', headers=headers).text
    soup = BeautifulSoup(html, 'lxml')
    li_list = soup.find('div', id='content').find_all('li')
    for li in li_list:
        span = li.find('div', class_='info').find('a').find('span', class_='title')
        print(span.text.strip())
```
> 注：一般在使用requests爬取页面时需要在请求头中添加User-Agent项以模拟真实用户请求。
在使用链式查找时，如果上一个节点未找到（返回None），会报错。
### 2.3.5  使用正则匹配
JSON、XML或HTML这些属于格式化文本，有一定固定格式和相应的解析方法，当遇到非格式化文本或者，不方便使用格式化文本解析时，则可以使用正则匹配来提取具有特定特征的内容。
正则匹配一般是通过前后定界符加上特定的格式表述来匹配或查找这种特征的字符串。
例如，从一串文本中匹配或查找出所有电话号码（固定电话）。固定电话可以描述为以下特征组成：
- 开头3位或4位数字
- 连字符可有一个或没有
- 7位或八位数字
#### 正则表达式
正则表达式便是用一下特殊字符来表达数据特征的一种方法。正则表达式由元字符组成。
正则表达式使用的元字符及含义如下：
表3.5  正则匹配元字符

|元字符|解释|
|---|---|
|.|任意字符|
|\d|任意数字|
|\D|任意非数字|
|\w|任意字符或数字|
|\W|任意非字符及数字|
|\s|任意空白字符(包含空格或\n等)|
|\S|任意非空白字符|
|^|匹配开头|
|$|匹配结尾|
|{n,m}|匹配n-m个重复|
|*|匹配重复任意次(包含0次)|
|+|匹配重复至少一次|
|?|匹配0或1次|
|()|分组,获取需要的部分数据|
|\|或,|匹配多个pattern|
|\元字符|取消元字符转义|
#### Python正则匹配函数
Python中的正则匹配库为re。是一个Python自带的系统库。使用时只要import re即可。
Python中常用的正则匹配函数如表3.6所示。
表3.6  正则匹配函数

|正则函数|解释|
|---|---|
|re.findall()|查找所有，返回列表|
|re.match()|匹配，匹配开头，结合re.group()使用|
|re.search()|搜索，从整个字符串中查找，结合re.group()使用|
|re.sub()/re.subn()|替换|
|re.split()|分割|
|re.compile()|编译以加快匹配|
#### Python正则表达式使用示例
假设我们要匹配从网址中匹配www字符串，从中查找com字符串，从一个字符串中查找a后面为数字的字符串部分，以及匹配一个由3到4位区号，有无横线均可，后面为7到8位数字的国内固定电话号码，示例如下：
代码parse_with_regex_pattern.py内容
```python
import re

print(re.match('www','www.baidu.com').group())
print(re.search('com','www.baidu.com').group())
print(re.findall(r'a\d+', 'daba4f5ag3a568a'))
print(re.findall(r'\d{3,4}-?\d{7,8}', '电话：010-12345678'))
print(re.findall(r'\d{3,4}-?\d{7,8}', '电话：037112345678'))
```
运行查看匹配结果：
```bash
www
com
['a4', 'a568']
['010-12345678']
['037112345678']
```
### 2.3.6  使用JSONPath解析复杂JSON
当遇到多层嵌套及格式较为复杂的JSON格式的响应时，将响应数据转为字典格式后，往往要进行多次循环遍历才能取到相应的数据，如：
```python
res_dict = {
    "code": 0,
    "msg": "成功",
    "data": {
        "users": [
            {"name": "张三", "gender": "male", "age": 12},
            {"name": "李四", "gender": "female", "age": 15},
            {"name": "王五", "gender": "male", "age": 22},
            {"name": "赵六", "gender": "male", "age": 24},
        ],
        "goods": [
            {"name": "apple", "price": 15, "num": 200},
            {"name": "pear", "price": 18, "num": 100},
            {"name": "banana", "price": 16, "num": 210},
        ]
    }
}
```
 1. 获取所有用户名?
 2. 如果users是动态的(有可能是users123,或users567)怎么获取下面的数据?
 3. 怎么快说获取年龄大于20的用户?
这种类型的操作用字典遍历往往就麻烦的多, 特别是遇到动态节点更是无从下手
JSONPath则可以很好的解决这个问题。
#### JSONPath的主要特点
- 支持路径及*模糊匹配
- 支持索引和类似切片功能
- 支持表达式筛选
#### 安装方法
JSONPath使用使用pip安装接口，命令如下：
```bash
$ pip install jsonpath
```
#### 基本语法
表3-4  JSONPath基本语法

|XPath|JSONPath|解释|
|---|---|---|
|/|$|跟节点|
|.|@|现行节点|
|/|. or []|取子节点|
|..|n/a|就是不管位置，选择所有符合条件的条件|
|*|*|匹配所有元素节点|
|[]|[]|迭代器标示(可以在里面做简单的迭代操作，如数组下标，根据内容选值等)|
|&#124|[,]|支持迭代器中做多选|
|[]|?()|支持过滤操作|
|n/a|()|支持表达式计算|
|()|n/a|分组，JSONPath不支持|
XPath是XML和HTML的路径选择语言，JSONPath是一种JSON格式的路径查找语言。即可以通过$一级一级节点往下查找，也支持任意节点的模糊查找以及条件查找。在Python版的JSONPath中，需要将JSON字符串转为字典，再通过JSONPath进行匹配，如果匹配到，返回所有结果的节点列表，否则返回False。示例如下：
代码parse_data_with_jsonpath.py内容
```python
from jsonpath import jsonpath

res_dict = {
    "code": 0,
    "msg": "成功",
    "data": {
        "users": [
            {"name": "张三", "gender": "male", "age": 12},
            {"name": "李四", "gender": "female", "age": 15},
            {"name": "王五", "gender": "male", "age": 22},
            {"name": "赵六", "gender": "male", "age": 24},
        ],
        "goods": [
            {"name": "apple", "price": 15, "num": 200},
            {"name": "pear", "price": 18, "num": 100},
            {"name": "banana", "price": 16, "num": 210},
        ]
    }
}
# 匹配结果为一个列表, 无结果返回False
# 1. 逐级取值, 可使用*代表任意节点 .. 表示任意路径
print(jsonpath(res_dict, "$.msg")) 
print(jsonpath(res_dict, "$.data.*"))
print(jsonpath(res_dict, "$.data..[2]")
print(jsonpath(res_dict, "$..users[*].name"))
# 2. 索引和切片
print(jsonpath(res_dict, "$.data.users[2]"))
print(jsonpath(res_dict, "$.data.users[0:2]"))
# 表达式
print(jsonpath(res_dict, "$..users[?(@.gender=='female')]"))
```
其中，`$.msg`指取跟节点下的msg字段的指，即“成功”；
`$.data.`*为取根节点下data下的任意节点的数据；
`$..users[*].name`为取任意节点下users节点任意列表项下的name字段，返回所有的name字段组成的列表。
`$.data.users[2]`为取根节点下data节点的第三个用户数据，索引从0开始。
`$.data.users[0:2]`为取根节点下data节点第一条和第二条数据
`$..users[?(@.gender=='female')]`为条件查找任意users节点下任意项的gender属性为female的数据，Python版的JSONPath的条件表达式中不支持引入$和当前数据的某一变量比较。

运行并查看数据：
```bash
['成功']
[[{'name': '张三', 'gender': 'male', 'age': 12}, {'name': '李四', 'gender': 'female', 'age': 15}, {'name': '王五', 'gender': 'male', 'age': 22}, {'name': '赵六', 'gender': 'male', 'age': 24}], [{'name': 'apple', 'price': 15, 'num': 200}, {'name': 'pear', 'price': 18, 'num': 100}, {'name': 'banana', 'price': 16, 'num': 210}]]
[{'name': '王五', 'gender': 'male', 'age': 22}, {'name': 'banana', 'price': 16, 'num': 210}]
['张三', '李四', '王五', '赵六']
[{'name': '王五', 'gender': 'male', 'age': 22}]
[{'name': '张三', 'gender': 'male', 'age': 12}, {'name': '李四', 'gender': 'female', 'age': 15}]
[{'name': '李四', 'gender': 'female', 'age': 15}]
```
### 2.3.7  使用JSONSchema验证JSON结构
对于复杂的JSON结构，虽然可以使用JSONPath快速提取相应的值。然而对于JSON响应的整体结构和各字段类型，使用JSONSchema验证更加方便。
安装方法：
```bash
$ pip install jsonschema
```
以上例中的响应结果为例：
```json
{
  "args": {
    "age": "12",
    "name": "Kevin"
  },
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.22.0",
    "X-Amzn-Trace-Id": "Root=1-5e7f618f-30ba932936a4a8e64ef5ea06"
  },
  "origin": "111.202.167.11",
  "url": "https://httpbin.org/get?name=Kevin&age=12"
}
```
整个JSON结构可以描述为，整体为object类型，包含args、headers、orgin、url四个属性，其中args、headers是object类型，origin、url是字符串类型，使用JSONSchema语法描述如下：
```json
{
    "type": "object",
    "properties": {
        "args": {"type": "object"},
        "headers": {"type": "object"},
        "origin": {"type": "string"},
        "url": {"type": "string"}
    }
}
```
对于object对象，还可以使用required描述必须存在的属性。对于args、headers还可以继续添加properties描述其子属性，对于字符串还可以使用patten字段描述其符合的真正表达式。
JSONSchema中的类型分为string、number、integer、array、object、boolean、null七种类型。其中，number包含整数和浮点数，integer仅限整数。JSONSchema每种类型常用的关键字如表3.3所示。
表3.3 JSONSchema各种类型支持的字段

| 类型 | 关键字 | 说明 |
| ---- | ---- | ---- |
| 最外层 | $schema | 指定使用的JSONSchema协议版本 |
| title | 规则标题 |  |
| description | 规则描述 |  |
| 通用 | type | 类型，string、number、integer、array、object、boolean、null |
| string | miniLength | 最小长度 |
| maxLength | 最大长度 |  |
| pattern | 匹配的正则表达式 |  |
| number/integer | minimum | 最小值, 结合"exclusiveMinimum": True，不包含等于 |
| maximum | 最大值，结合"exclusiveMaximum": True，不包含等于 |  |
| multipleOf | 可被指定数字整除 |  |
| object | properites | 子属性 |
| patternProperties | 子属性名满足正则表达式 |  |
| required | 必选子属性 |  |
| array | items | 子元素 |
| required | 必选子元素 |  |
| miniItems | 最少子元素个数 |  |
| maxItems | 最大子元素个数 |  |
完整示例如下：
代码requests_validate_with_jsonschema.py内容
```python
import requests
import jsonschema
res = requests.get('https://httpbin.org/get?name=Kevin&age=12')
schema = {
    "type": "object",
    "properties": {
        "args": {
            "type": "object",
            "required": ["name", "age"],
            "properties": {
                "name": {"type": "string", "pattern": "^Kevin$"},
                "age": {"type": "string", "pattern": "^12$"}
            }
        },
        "headers": {"type": "object"},
        "origin": {"type": "string", "pattern": "\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}"},
        "url": {"type": "string"}
    }
}
jsonschema.validate(res.json(), schema)
```
上例中，required限定，args必须有name和age两个子属性。
name字段的pattern使用“^Kevin$”表示，必须以K开头，以n结尾，即完全等于Kevin。
同样，断言通过时不会有任何输出，断言失败是则会抛出异常。
## 2.4  关联及接口依赖
接口依赖是指我们要请求的某个接口的请求报文需要其他接口的响应中获取。将上一个接口响应中的动态变量提取并组装到下一个接口的请求中的过程叫做关联。
接口依赖通常有状态依赖和数据依赖两种。
### 2.4.1  状态依赖及会话保持
状态依赖，指一个接口需要在一定状态下方能进行正常的业务使用，如投票接口必须在活动开启后才能正常投票，登录状态的用户才能正常请求购物车列表接口等等。
对于依赖登录状态的接口，我们可以使用requests的会话保持来维持请求的登录状态。
requests.get()或post()等方法每次使用时都会新建一个会话并发送请求。如果需要保持会话状态，可以先使用requests.session()新建一个会话，然后使用同一个会话发送不同的请求，示例如下：

> 代码requests_with_session.py内容
```python
import requests

session = requests.session()
url = 'http://115.28.108.130:5000/api/user/login/'
data = {'name': '张三', 'password': '123456'}
res = session.post(url, data=data)
print(res.text)
url2 = 'http://115.28.108.130:5000/api/user/getUserList/'
res2 = session.get(url2)
print(res2.text)
```
为了保持用户的登录状态，首先新建一个会话变量session，使用该会话发送登录请求，此时再使用该会话发送其他依赖登录状态的请求时便可正常使用。
### 2.4.2  数据依赖及关联
接口数据依赖的处理一遍分为三步：
 1. 请求所依赖接口
 2. 从响应数据中提取变量
 3. 使用变量组装报文发送请求
如下示例展示了一个百度OCR接口的使用方法，在使用该接口时首先要获取一个access_token。
代码requests_handle_related_api.py内容
```python
import requests

url = 'https://aip.baidubce.com/oauth/2.0/token?' \
          'grant_type=client_credentials&' \
          'client_id=<百度开发者平台client_id> &' \
          'client_secret=<百度开发者平台cleint_secret>'
res = requests.get(url)
token = res.json()['access_token']  # 中间变量的提取
url = f'https://aip.baidubce.com/rest/2.0/ocr/v1/general_basic?access_token={token}'
# params={'access_token': token}
play_load = {'url': 'http://upload-images.jianshu.io/upload_images/7575721-40c847532432e852.png? imageMogr2/auto-orient/strip%7CimageView2/2/w/1240'}
res = requests.post(url, data=play_load)
print(res.json())
```
### 使用Mock或Mock Server
Mock即模拟，用来临时构造并替代一些复杂对象或数据。Mock Server即Mock数据服务器，提供各种Mock数据接口。
以下情况下可以考虑使用Mock数据：
 1. 所依赖接口尚未搭建好，或不稳定影响测试。
 2. 依赖三方接口或所依赖条件复杂，依赖接口不作为测试点。
 3. 需要构造比较复杂的请求数据，如参数需要有效手机号、IP、URL等。
#### 使用Faker模拟数据
除了随机的数字、字符串之外，在实际测试中往往需要不同形式的数据，如用户名、密码、地址、链接等等。使用Python的三方库faker可以快速生成各种形式的模拟（假）数据。
Faker的安装方法如下：
```bash
$ pip install faker
```
使用faker首先要指定使用的语言并生成一个实例对象，然后即可使用不同的函数生成不同形式的模拟数据。faker提供的数据方法非常多，常用的如：
- name()：生成随机名称。
- password()：生成随机密码。
- email()：生成随机邮件。
- address()：生成随机地址。
- ipv4()：生成随机IPv4地址。
- file_name()：生成随机文件名。
- unix_time()：生成随机时间戳。
- md5()：生成随机md5值。
- text()：生成一段随机文字。
简单使用示例如下：
代码python_facker_data.py内容
```python
import faker
import requests

f = faker.Faker(locale='zh-CN')
url = 'https://httpbin.org/post'
data = {'name': f.name(), 'password': f.password(), 'email': f.email()}
res = requests.post(url, data=data)
print(res.text)
```
更多的生成函数方法可以参考：https://faker.readthedocs.io/en/master/locales/zh_CN.html
#### 使用Mock Server
一般的接口管理平台（如YAPI，RAP）都具有Mock的功能，如果没有相应的Mock平台也可以使用Fiddler抓包工具的自动响应实现Mock功能。另外也可以自己编写Mock接口使用，例如我们可以使用Flask编写简单的Mock接口。
首先在命令行使用以下命令安装Flask：
```bash
$ pip install flask
```
使用Flask编写的简单Mock接口示例如下：
代码flask_mock_api.py内容
```python
import random
from flask import Flask,jsonify

app = Flask('mock')
@app.route('/api/login', methods=['POST'])
def mock_login():   # 模拟登录接口
    res_list = [{'code': 0, 'msg': 'success'},
             {'code': 1, 'msg': 'username not found'},
             {'code': 2, 'msg': 'password wrong'}]
    res = random.choice(res_list)  # 随机返回一个响应内容
    return jsonify(res)  # 转为JSON响应格式返回
if __name__ == '__main__':
    app.run()   # 启动服务
```
运行脚本便可使用该接口进行测试。
## 2.5  并发请求及异步接口轮询
有时候我们需要测试接口在并发情况下的状态，另外有些接口是异步的，即对于耗时的业务首先返回个事件id，可以通过该事件id来查询业务是否处理完成。
### 2.5.1  并发请求
在大量的请求中，为了提高效率，并发请求是必不可少的。requests本身并不支持异步。想要并发请求常用的有多线程、多进程或gevent方式。
1．多线程并发请求
直接使用threading的Thread对象即可，通过target指定要运行的方法，示例如下：
代码requests_with_threads.py内容
```python
import requests
from threading import Thread

def print_res(res, *args, **kwargs):
    print(res.text)
s = requests.Session()
s.hooks={'response': print_res}
t1 = Thread(target=s.get, args=('https://httpbin.org/get',)) # 指定线程运行方法
t2 = Thread(target=s.post, args=('https://httpbin.org/post',), kwargs={'data': {'a': 1}})
t1.start() # 启动线程
t2.start()
t1.join()  # 连接主线程
t2.join() 
```
默认线程运行无法获取target函数的运行结果，这里给会话添加了默认hooks方法，来打印响应文本（也可以通过自定义请求方法来实现）。
如果想获取线程结果，需要继承Thread并编写自己的线程处理类，示例如下：
代码requests_with_custom_threads.py内容
```python
import requests
from threading import Thread

class MyThread(Thread):
    def __init__(self, func, *args, **kwargs):  # 改变线程的使用方式，可以直接传递函数方法和函数参数
        super(MyThread, self).__init__()
        self.func = func
        self.args = args
        self.kwargs = kwargs
        self.result = None
    def run(self):
        self.result = self.func(*self.args, **self.kwargs)  # 为线程添加属性result存储运行结果
t1 = MyThread(requests.get, 'https://httpbin.org/get')
t2 = MyThread(requests.post, 'https://httpbin.org/post', data={'a':1})
t1.start()
t2.start()
t1.join()
t2.join()
print(t1.result)  # 响应对象
print(t2.result.text)  # 响应对象的text属性即响应文本
```
#### 使用gevent并发请求
首先要安装gevent，安装方法如下：
```bash
$ pip install gevent
```
使用示例如下：

> 代码requests_with_gevent.py内容
```python
from gevent import monkey;monkey.patch_all()  # 要放import requests上面
import requests
import gevent

g1 = gevent.spawn(requests.get, 'https://httpbin.org/get')
g2 = gevent.spawn(requests.post, 'https://httpbin.org/post', data={'a': 1})
gevent.joinall([g1, g2])
print(g1.value)  # 响应对象
print(g2.value)
```
#### 使用grequests并发请求
grequests是gevent和requests的结合体，使用grequests并发请求会更加方便。首先要先安装grequests。
```bash
$ pip install grequests
```
使用示例如下：

> 代码use_grequests.py内容
```python
import grequests

req_list = [
  grequests.get('https://httpbin.org/get', ), 
  grequests.post('https://httpbin.org/post', data={'a': 1})
]
res_list = grequests.map(req_list)
print(res_list)
```
### 2.5.2  异步接口轮询
当业务处理耗费时间较长时，接口一般会采用异步处理的方式。先返回处理中和相应id，并提供通过id查询业务结果的接口。我们需要不断去请求查询结果接口，直到其返回了期望的结果。
这种间隔一定时间，不断的去查询某个接口的操作叫做轮询。为避免请求长时间无法返回期望结果，一般需要设置最大轮询次数或设置最长轮询时间。假设获取请求结果的接口为https://httpbin.org/get?id=5，业务未处理完时，响应中无result字段，业务处理完后响应中result字段显示处理结果。假设我们每隔1秒轮询一次，最多轮询10次，示例如下：
代码requests_async_api.py内容
```python
import requests
from time import sleep

for i in range(10):
    res = requests.get('https://httpbin.org/get?id=5')
    result = res.json().get('result')
    print('执行第%d次轮询' % (i+1), 'result:', result )
    if result :
        break
    sleep(1)
else:
    print('未获取到结果')
```
以上示例中，设定了最大循环次数为10，如果期望条件满足，则会跳出循环，否则等待1秒后继续请求。当循环以非break退出时执行else段，打印未获取到结果。
> 注：该示例接口并不具备真实的异步处理功能，因此返回的结果并不会出现result字段。

## 4.6  小结
本章主要讲解了Python Requests库的使用，以及各种类型接口的请求发送、参数化及响应的解析。对于层级较多的JSON响应，可以使用JSONPath进行解析。对于XML/HTML格式可以使用Element Tree进行解析，对于非结构化文本，可以使用正则表达式进行提取。
此外，本章还讲解了接口依赖、异步接口的处理，Mock的使用及Web Service接口怎么测试。
